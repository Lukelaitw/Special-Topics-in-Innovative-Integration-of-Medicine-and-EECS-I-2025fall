{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65dd3d95-ae1b-4c5e-a27c-cc64392d1a7a",
   "metadata": {},
   "source": [
    "# Detection of Alzheimer's Disease Using Graph Signal Processing of EEG Recordings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb5470-a53f-4426-a2eb-0d2b97fd28b6",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Link here: https://openneuro.org/datasets/ds004504/versions/1.0.6\n",
    "\n",
    "### Participants:\n",
    "- **Total subjects: 88**\n",
    "  - **Alzheimer's disease (AD group): 36**\n",
    "    - Average MMSE: 17.75 (sd=4.5)\n",
    "    - Mean age: 66.4 (sd=7.9)\n",
    "    - Median disease duration: 25 months, IQR: 24 - 28.5\n",
    "  - **Frontotemporal Dementia (FTD group): 23**\n",
    "    - Average MMSE: 22.17 (sd=8.22)\n",
    "    - Mean age: 63.6 (sd=8.2)\n",
    "  - **Healthy subjects (CN group): 29**\n",
    "    - Average MMSE: 30\n",
    "    - Mean age: 67.9 (sd=5.4)\n",
    "- **MMSE score ranges:** 0 to 30 (lower scores indicate more severe decline)\n",
    "\n",
    "### Recordings:\n",
    "- **Location:** 2nd Department of Neurology of AHEPA General Hospital, Thessaloniki\n",
    "- **Device:** Nihon Kohden EEG 2100 clinical device, 19 scalp electrodes, 2 reference electrodes\n",
    "- **Parameters:** 500 Hz sampling rate, 10uV/mm resolution, sensitivity 10uV/mm, time constant 0.3s, high-frequency filter at 70 Hz\n",
    "- **Duration:** \n",
    "  - AD group: 13.5 minutes (min=5.1, max=21.3)\n",
    "  - FTD group: 12 minutes (min=7.9, max=16.9)\n",
    "  - CN group: 13.8 minutes (min=12.5, max=16.5)\n",
    "- **Total recordings:**\n",
    "  - AD: 485.5 minutes\n",
    "  - FTD: 276.5 minutes\n",
    "  - CN: 402 minutes\n",
    "\n",
    "### Preprocessing:\n",
    "- **Exported to:** .eeg format, transformed to BIDS accepted .set format\n",
    "- **Unprocessed recordings in folders named:** sub-0XX\n",
    "- **Preprocessed and denoised recordings in sub-0XX within subfolder derivatives**\n",
    "- **Preprocessing pipeline:**\n",
    "  - Butterworth band-pass filter 0.5-45 Hz\n",
    "  - Re-referenced to A1-A2\n",
    "  - Artifact Subspace Reconstruction (ASR) applied\n",
    "  - Independent Component Analysis (ICA) method performed, transformed to 19 ICA components\n",
    "  - Eye and jaw artifacts automatically rejected\n",
    "- **Automatic annotations of artifacts not included for language compatibility**\n",
    "- **Preprocessed dataset available in Folder:** derivatives\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Same as in [Detection of Epilepsy Using Graph Signal Processing of EEG Signals with Three Features](https://link.springer.com/chapter/10.1007/978-981-19-1520-8_46)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197c795-6c35-469d-a775-954ab415c3a9",
   "metadata": {},
   "source": [
    "## GSP Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3491b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CuPy 已安裝，將使用 GPU 加速\n",
      "GPU 設備數量: 1\n",
      "使用 GPU 設備: 0\n"
     ]
    }
   ],
   "source": [
    "# 安裝和配置 CuPy（GPU 加速的 NumPy）\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# 檢查是否有 GPU\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    has_cuda = result.returncode == 0\n",
    "except:\n",
    "    has_cuda = False\n",
    "\n",
    "# 嘗試導入 CuPy\n",
    "try:\n",
    "    import cupy as cp\n",
    "    USE_GPU = True\n",
    "    print(\"✓ CuPy 已安裝，將使用 GPU 加速\")\n",
    "    print(f\"GPU 設備數量: {cp.cuda.runtime.getDeviceCount()}\")\n",
    "except ImportError:\n",
    "    USE_GPU = False\n",
    "    if has_cuda:\n",
    "        print(\"正在安裝 CuPy（GPU 加速的 NumPy）...\")\n",
    "        # 根據 CUDA 版本安裝對應的 CuPy\n",
    "        # 可以根據需要調整版本，這裡使用通用版本\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"cupy-cuda11x\"])\n",
    "        import cupy as cp\n",
    "        USE_GPU = True\n",
    "        print(\"✓ CuPy 安裝完成，將使用 GPU 加速\")\n",
    "    else:\n",
    "        print(\"未檢測到 GPU，將使用 CPU（NumPy）\")\n",
    "        cp = None\n",
    "\n",
    "# 設置默認設備\n",
    "if USE_GPU:\n",
    "    # 使用 GPU 0\n",
    "    cp.cuda.Device(0).use()\n",
    "    print(f\"使用 GPU 設備: {cp.cuda.Device(0).id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6304052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ pandas 已安裝\n",
      "✓ numpy 已安裝\n",
      "✓ mne 已安裝\n",
      "✓ pygsp 已安裝\n",
      "✓ scipy 已安裝\n",
      "✓ networkx 已安裝\n",
      "✓ scikit-learn 已安裝\n",
      "✓ seaborn 已安裝\n",
      "✓ matplotlib 已安裝\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b12901075/miniconda3/envs/bci_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ umap-learn 已安裝\n"
     ]
    }
   ],
   "source": [
    "# 安裝所需的套件\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# 需要安裝的套件列表\n",
    "packages = [\n",
    "    'pandas',           # 數據處理\n",
    "    'numpy',            # 數值計算\n",
    "    'mne',              # MNE-Python - 神經科學數據分析\n",
    "    'pygsp',            # PyGSP - 圖信號處理\n",
    "    'scipy',            # 科學計算庫\n",
    "    'networkx',         # 圖網絡分析\n",
    "    'scikit-learn',     # 機器學習庫 (sklearn)\n",
    "    'seaborn',          # 數據可視化\n",
    "    'matplotlib',       # 繪圖庫\n",
    "    'umap-learn'        # UMAP 降維 (導入時使用 import umap)\n",
    "]\n",
    "\n",
    "# 安裝套件\n",
    "for package in packages:\n",
    "    try:\n",
    "        # 處理特殊情況：包名和導入名不同\n",
    "        if package == 'scikit-learn':\n",
    "            import_name = 'sklearn'\n",
    "        elif package == 'umap-learn':\n",
    "            import_name = 'umap'\n",
    "        else:\n",
    "            import_name = package\n",
    "        __import__(import_name)\n",
    "        print(f\"✓ {package} 已安裝\")\n",
    "    except ImportError:\n",
    "        print(f\"正在安裝 {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✓ {package} 安裝完成\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898bf272-d2da-457e-bb03-ca5c60841311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "from pygsp import graphs, utils\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.stats import entropy\n",
    "import networkx as nx\n",
    "from sklearn.cluster import spectral_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c9a37ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 .set files.\n",
      "Processing /home/b12901075/eecsmed/ds004504/derivatives/sub-011/eeg/sub-011_task-eyesclosed_eeg.set (1/88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw = mne.io.read_raw_eeglab(file)\n",
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/b12901075/eecsmed/ds004504/derivatives/sub-088/eeg/sub-088_task-eyesclosed_eeg.set (2/88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw = mne.io.read_raw_eeglab(file)\n",
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/b12901075/eecsmed/ds004504/derivatives/sub-045/eeg/sub-045_task-eyesclosed_eeg.set (3/88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw = mne.io.read_raw_eeglab(file)\n",
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/b12901075/eecsmed/ds004504/derivatives/sub-038/eeg/sub-038_task-eyesclosed_eeg.set (4/88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw = mne.io.read_raw_eeglab(file)\n",
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/b12901075/eecsmed/ds004504/derivatives/sub-002/eeg/sub-002_task-eyesclosed_eeg.set (5/88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw = mne.io.read_raw_eeglab(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/b12901075/eecsmed/ds004504/derivatives/sub-068/eeg/sub-068_task-eyesclosed_eeg.set (6/88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw = mne.io.read_raw_eeglab(file)\n",
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/b12901075/eecsmed/ds004504/derivatives/sub-030/eeg/sub-030_task-eyesclosed_eeg.set (7/88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw = mne.io.read_raw_eeglab(file)\n",
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/b12901075/eecsmed/ds004504/derivatives/sub-087/eeg/sub-087_task-eyesclosed_eeg.set (8/88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw = mne.io.read_raw_eeglab(file)\n",
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/b12901075/eecsmed/ds004504/derivatives/sub-040/eeg/sub-040_task-eyesclosed_eeg.set (9/88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw = mne.io.read_raw_eeglab(file)\n",
      "/tmp/ipykernel_2460785/311776220.py:49: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(file)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m G \u001b[38;5;241m=\u001b[39m graphs\u001b[38;5;241m.\u001b[39mGraph(W)\n\u001b[1;32m     63\u001b[0m L \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39mL\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m---> 64\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m X_GdataT \u001b[38;5;241m=\u001b[39m eigenvectors\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m data\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     66\u001b[0m C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcov(X_GdataT)\n",
      "File \u001b[0;32m~/miniconda3/envs/bci_env/lib/python3.10/site-packages/numpy/linalg/_linalg.py:1627\u001b[0m, in \u001b[0;36meigh\u001b[0;34m(a, UPLO)\u001b[0m\n\u001b[1;32m   1623\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->dD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->dd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call\u001b[38;5;241m=\u001b[39m_raise_linalgerror_eigenvalues_nonconvergence,\n\u001b[1;32m   1625\u001b[0m               invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m, over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1626\u001b[0m               under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1627\u001b[0m     w, vt \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1628\u001b[0m w \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1629\u001b[0m vt \u001b[38;5;241m=\u001b[39m vt\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_total_variation(W, data_values):\n",
    "    \"\"\"\n",
    "    向量化版本的总变分计算，比双重循环快得多\n",
    "    \n",
    "    总变分公式: TV = sqrt(sum_{i,j} w_{ij} * ||x_j - x_i||^2)\n",
    "    \"\"\"\n",
    "    # 使用广播计算所有 (i,j) 对的差值\n",
    "    # data_values[i] 形状: (D,), data_values[j] 形状: (D,)\n",
    "    # 我们需要计算所有 i,j 对的差值\n",
    "    N = data_values.shape[0]\n",
    "    \n",
    "    # 方法1: 使用广播 (更高效)\n",
    "    # 扩展维度: data_values[i] -> (N, 1, D), data_values[j] -> (1, N, D)\n",
    "    data_i = data_values[:, np.newaxis, :]  # (N, 1, D)\n",
    "    data_j = data_values[np.newaxis, :, :]  # (1, N, D)\n",
    "    \n",
    "    # 计算所有差值: (N, N, D)\n",
    "    differences = data_j - data_i\n",
    "    \n",
    "    # 计算每个差值的 L2 范数的平方: (N, N)\n",
    "    squared_norms = np.sum(differences ** 2, axis=2)\n",
    "    \n",
    "    # 与权重矩阵相乘并求和\n",
    "    TV = np.sum(W * squared_norms)\n",
    "    \n",
    "    return np.sqrt(TV)\n",
    "\n",
    "dir_path = r'/home/b12901075/eecsmed/ds004504/derivatives'\n",
    "file_list = [\n",
    "    os.path.join(root, file) \n",
    "    for root, dirs, files in os.walk(dir_path) \n",
    "    for file in files \n",
    "    if file.endswith(\".set\")\n",
    "]\n",
    "\n",
    "n_files = len(file_list)\n",
    "if n_files == 0:\n",
    "    raise ValueError(f\"No .set files found in directory {dir_path}.\")\n",
    "\n",
    "print(f'Found {n_files} .set files.')\n",
    "\n",
    "channel_names = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']\n",
    "\n",
    "data_list = []\n",
    "features = {}\n",
    "\n",
    "for i, file in enumerate(file_list):\n",
    "    print(f'Processing {file} ({i+1}/{n_files})')\n",
    "    raw = mne.io.read_raw_eeglab(file)\n",
    "    data = raw.get_data(picks=channel_names)\n",
    "    transposed_data = np.transpose(data)\n",
    "    data = pd.DataFrame(transposed_data, columns=channel_names)\n",
    "    data = data.groupby(data.index // 50).median()\n",
    "    data_list.append(data)\n",
    "\n",
    "    # GSP analysis\n",
    "    distances = distance_matrix(data.values, data.values)\n",
    "    theta, k = 1.0, 1.0 \n",
    "    W = np.exp(-distances**2 / theta**2)\n",
    "    W[distances > k] = 0\n",
    "    np.fill_diagonal(W, 0)\n",
    "    G = graphs.Graph(W)\n",
    "    L = G.L.toarray()\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(L)\n",
    "    X_GdataT = eigenvectors.T @ data.values\n",
    "    C = np.cov(X_GdataT)\n",
    "    T = eigenvectors.T.conj() @ C @ eigenvectors\n",
    "    r = np.linalg.norm(np.diag(T)) / np.linalg.norm(T, 'fro')\n",
    "    P = L @ data.values\n",
    "    Y = np.sum(data.values * P)**2\n",
    "    TV = compute_total_variation(W, data.values)\n",
    "\n",
    "    # Spectral Graph Features\n",
    "    graph_energy = np.sum(np.abs(eigenvalues))\n",
    "    # 计算 spectral entropy：使用特征值的归一化分布作为概率分布\n",
    "    # 将特征值转换为非负值并归一化\n",
    "    eigenvals_abs = np.abs(eigenvalues)\n",
    "    eigenvals_normalized = eigenvals_abs / (np.sum(eigenvals_abs) + 1e-10)  # 添加小值避免除零\n",
    "    spectral_entropy = entropy(eigenvals_normalized)\n",
    "\n",
    "    # Graph Signal Features\n",
    "    signal_energy = np.sum(np.square(data.values))\n",
    "    signal_power = np.var(data.values)\n",
    "\n",
    "    # Graph Modularity and Community Structure\n",
    "    labels = spectral_clustering(W)\n",
    "    unique_labels = len(np.unique(labels))\n",
    "\n",
    "    # Graph Degree Distribution\n",
    "    degree_distribution = np.sum(W, axis=0)\n",
    "\n",
    "    # Graph Diffusion Characteristics\n",
    "    heat_trace = np.trace(np.exp(-L))\n",
    "    diffusion_distance = np.sum(np.exp(-L))\n",
    "\n",
    "    # Aggregating Features\n",
    "    features[os.path.basename(file)] = {\n",
    "        'stationary_ratio': r, \n",
    "        'Tik-norm': Y, \n",
    "        'Total_Variation': TV,\n",
    "        'graph_energy': graph_energy,\n",
    "        'spectral_entropy': spectral_entropy,\n",
    "        'signal_energy': signal_energy,\n",
    "        'signal_power': signal_power,\n",
    "        'unique_clusters': unique_labels,\n",
    "        'avg_degree': np.mean(degree_distribution),\n",
    "        'heat_trace': heat_trace,\n",
    "        'diffusion_distance': diffusion_distance\n",
    "    }\n",
    "\n",
    "features_data = pd.DataFrame(features).T\n",
    "features_data.to_csv('features_tv.csv', index_label='participant_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d814ca07-266b-430e-9d61-3eb7d8b71760",
   "metadata": {},
   "source": [
    "## Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb51153b-82a9-4f0b-a2f0-7ea2f2e4692d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id_x</th>\n",
       "      <th>stationary_ratio</th>\n",
       "      <th>Tik-norm</th>\n",
       "      <th>Total_Variation</th>\n",
       "      <th>graph_energy</th>\n",
       "      <th>spectral_entropy</th>\n",
       "      <th>signal_energy</th>\n",
       "      <th>signal_power</th>\n",
       "      <th>unique_clusters</th>\n",
       "      <th>avg_degree</th>\n",
       "      <th>heat_trace</th>\n",
       "      <th>diffusion_distance</th>\n",
       "      <th>participant_id_y</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Group</th>\n",
       "      <th>MMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-011_task-eyesclosed_eeg.set</td>\n",
       "      <td>0.065765</td>\n",
       "      <td>1.472647</td>\n",
       "      <td>1.557900</td>\n",
       "      <td>5.928230e+07</td>\n",
       "      <td>8.948846</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>1.077305e-09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7698.999685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.611460e+08</td>\n",
       "      <td>sub-001</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-088_task-eyesclosed_eeg.set</td>\n",
       "      <td>0.037262</td>\n",
       "      <td>1.189033</td>\n",
       "      <td>1.476772</td>\n",
       "      <td>6.156756e+07</td>\n",
       "      <td>8.967759</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>9.320460e-10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7845.999722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.673580e+08</td>\n",
       "      <td>sub-002</td>\n",
       "      <td>F</td>\n",
       "      <td>78</td>\n",
       "      <td>A</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-045_task-eyesclosed_eeg.set</td>\n",
       "      <td>0.063532</td>\n",
       "      <td>2.015106</td>\n",
       "      <td>1.684959</td>\n",
       "      <td>7.253077e+07</td>\n",
       "      <td>9.049702</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1.029976e-09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8515.999667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.971591e+08</td>\n",
       "      <td>sub-003</td>\n",
       "      <td>M</td>\n",
       "      <td>70</td>\n",
       "      <td>A</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-038_task-eyesclosed_eeg.set</td>\n",
       "      <td>0.057751</td>\n",
       "      <td>1.793222</td>\n",
       "      <td>1.636528</td>\n",
       "      <td>7.945048e+07</td>\n",
       "      <td>9.095266</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>8.870028e-10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8912.999700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.159688e+08</td>\n",
       "      <td>sub-004</td>\n",
       "      <td>F</td>\n",
       "      <td>67</td>\n",
       "      <td>A</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-002_task-eyesclosed_eeg.set</td>\n",
       "      <td>0.036089</td>\n",
       "      <td>1.152527</td>\n",
       "      <td>1.465304</td>\n",
       "      <td>6.289283e+07</td>\n",
       "      <td>8.978408</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>8.982981e-10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7929.999729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.709604e+08</td>\n",
       "      <td>sub-005</td>\n",
       "      <td>M</td>\n",
       "      <td>70</td>\n",
       "      <td>A</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>sub-015_task-eyesclosed_eeg.set</td>\n",
       "      <td>0.044033</td>\n",
       "      <td>2.469593</td>\n",
       "      <td>1.772847</td>\n",
       "      <td>8.124318e+07</td>\n",
       "      <td>9.106423</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1.017948e-09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9012.999651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.208419e+08</td>\n",
       "      <td>sub-084</td>\n",
       "      <td>F</td>\n",
       "      <td>71</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>sub-027_task-eyesclosed_eeg.set</td>\n",
       "      <td>0.031677</td>\n",
       "      <td>2.338241</td>\n",
       "      <td>1.748789</td>\n",
       "      <td>6.825238e+07</td>\n",
       "      <td>9.019301</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1.179025e-09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8260.999630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.855292e+08</td>\n",
       "      <td>sub-085</td>\n",
       "      <td>M</td>\n",
       "      <td>64</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>sub-003_task-eyesclosed_eeg.set</td>\n",
       "      <td>0.048940</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.516504</td>\n",
       "      <td>9.366660e+06</td>\n",
       "      <td>8.026170</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>7.492876e-10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3059.999913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.546122e+07</td>\n",
       "      <td>sub-086</td>\n",
       "      <td>M</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>sub-057_task-eyesclosed_eeg.set</td>\n",
       "      <td>0.031148</td>\n",
       "      <td>1.485881</td>\n",
       "      <td>1.561389</td>\n",
       "      <td>6.343326e+07</td>\n",
       "      <td>8.982687</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>1.011276e-09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7963.999694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.724295e+08</td>\n",
       "      <td>sub-087</td>\n",
       "      <td>M</td>\n",
       "      <td>73</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>sub-018_task-eyesclosed_eeg.set</td>\n",
       "      <td>0.036481</td>\n",
       "      <td>2.282894</td>\n",
       "      <td>1.738347</td>\n",
       "      <td>7.141095e+07</td>\n",
       "      <td>9.041922</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>1.113459e-09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8449.999642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.941151e+08</td>\n",
       "      <td>sub-088</td>\n",
       "      <td>M</td>\n",
       "      <td>55</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   participant_id_x  stationary_ratio  Tik-norm  \\\n",
       "0   sub-011_task-eyesclosed_eeg.set          0.065765  1.472647   \n",
       "1   sub-088_task-eyesclosed_eeg.set          0.037262  1.189033   \n",
       "2   sub-045_task-eyesclosed_eeg.set          0.063532  2.015106   \n",
       "3   sub-038_task-eyesclosed_eeg.set          0.057751  1.793222   \n",
       "4   sub-002_task-eyesclosed_eeg.set          0.036089  1.152527   \n",
       "..                              ...               ...       ...   \n",
       "83  sub-015_task-eyesclosed_eeg.set          0.044033  2.469593   \n",
       "84  sub-027_task-eyesclosed_eeg.set          0.031677  2.338241   \n",
       "85  sub-003_task-eyesclosed_eeg.set          0.048940  0.017792   \n",
       "86  sub-057_task-eyesclosed_eeg.set          0.031148  1.485881   \n",
       "87  sub-018_task-eyesclosed_eeg.set          0.036481  2.282894   \n",
       "\n",
       "    Total_Variation  graph_energy  spectral_entropy  signal_energy  \\\n",
       "0          1.557900  5.928230e+07          8.948846       0.000158   \n",
       "1          1.476772  6.156756e+07          8.967759       0.000139   \n",
       "2          1.684959  7.253077e+07          9.049702       0.000167   \n",
       "3          1.636528  7.945048e+07          9.095266       0.000150   \n",
       "4          1.465304  6.289283e+07          8.978408       0.000135   \n",
       "..              ...           ...               ...            ...   \n",
       "83         1.772847  8.124318e+07          9.106423       0.000174   \n",
       "84         1.748789  6.825238e+07          9.019301       0.000185   \n",
       "85         0.516504  9.366660e+06          8.026170       0.000044   \n",
       "86         1.561389  6.343326e+07          8.982687       0.000153   \n",
       "87         1.738347  7.141095e+07          9.041922       0.000179   \n",
       "\n",
       "    signal_power  unique_clusters   avg_degree  heat_trace  \\\n",
       "0   1.077305e-09              8.0  7698.999685         0.0   \n",
       "1   9.320460e-10              8.0  7845.999722         0.0   \n",
       "2   1.029976e-09              8.0  8515.999667         0.0   \n",
       "3   8.870028e-10              8.0  8912.999700         0.0   \n",
       "4   8.982981e-10              8.0  7929.999729         0.0   \n",
       "..           ...              ...          ...         ...   \n",
       "83  1.017948e-09              8.0  9012.999651         0.0   \n",
       "84  1.179025e-09              8.0  8260.999630         0.0   \n",
       "85  7.492876e-10              8.0  3059.999913         0.0   \n",
       "86  1.011276e-09              8.0  7963.999694         0.0   \n",
       "87  1.113459e-09              8.0  8449.999642         0.0   \n",
       "\n",
       "    diffusion_distance participant_id_y Gender  Age Group  MMSE  \n",
       "0         1.611460e+08          sub-001      F   57     A    16  \n",
       "1         1.673580e+08          sub-002      F   78     A    22  \n",
       "2         1.971591e+08          sub-003      M   70     A    14  \n",
       "3         2.159688e+08          sub-004      F   67     A    20  \n",
       "4         1.709604e+08          sub-005      M   70     A    22  \n",
       "..                 ...              ...    ...  ...   ...   ...  \n",
       "83        2.208419e+08          sub-084      F   71     F    24  \n",
       "84        1.855292e+08          sub-085      M   64     F    26  \n",
       "85        2.546122e+07          sub-086      M   49     F    26  \n",
       "86        1.724295e+08          sub-087      M   73     F    24  \n",
       "87        1.941151e+08          sub-088      M   55     F    24  \n",
       "\n",
       "[88 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 设置数据路径\n",
    "base_dir = r'./'\n",
    "dataset_dir = os.path.join(base_dir, 'ds004504')\n",
    "\n",
    "# 读取特征数据\n",
    "features = pd.read_csv(os.path.join(base_dir, \"features_tv.csv\"))\n",
    "# 读取参与者信息\n",
    "participants = pd.read_csv(os.path.join(dataset_dir, \"participants.tsv\"), delimiter='\\t')\n",
    "data = features.merge(participants, left_index=True, right_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab4ce9-bd65-489e-83e6-6c445b855976",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36fd8c1-0494-453c-bdfb-60e5de53f0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group\n",
      "A    36\n",
      "C    29\n",
      "F    23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the frequency of each group\n",
    "group_frequencies = data['Group'].value_counts()\n",
    "print(group_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea41c9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70850a-29c6-4424-9712-a2e6a91ebbb7",
   "metadata": {},
   "source": [
    "## Multi-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98700103-8bea-45ac-af9d-eaa77dd6db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'stationary_ratio': 'Stationary Ratio',\n",
    "    'Tik-norm': 'Tik-norm',\n",
    "    'Total_Variation': 'Total Variation',\n",
    "    'graph_energy': 'Graph Energy',\n",
    "    'spectral_entropy': 'Spectral Entropy',\n",
    "    'signal_energy': 'Signal Energy',\n",
    "    'signal_power': 'Signal Power',\n",
    "    'avg_degree': 'Average Degree',\n",
    "    'diffusion_distance': 'Diffusion Distance',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3562cb8",
   "metadata": {},
   "source": [
    "### 階層式分類"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e8728b",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f496e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "數據分割信息\n",
      "============================================================\n",
      "總樣本數: 88\n",
      "訓練集樣本數: 30 (34.1%)\n",
      "驗證集樣本數: 31 (35.2%)\n",
      "測試集樣本數: 27 (30.7%)\n",
      "\n",
      "類別編碼: {'A': 0, 'C': 1, 'F': 2}\n",
      "訓練集類別分布: {'A': np.int64(12), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "驗證集類別分布: {'A': np.int64(13), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "測試集類別分布: {'A': np.int64(11), 'C': np.int64(9), 'F': np.int64(7)}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "階層式分類：步驟 1 - 健康 vs 疾病（二分類）\n",
      "============================================================\n",
      "\n",
      "驗證集結果:\n",
      "Balanced Accuracy: 0.4571\n",
      "混淆矩陣:\n",
      "[[15  6]\n",
      " [ 8  2]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    疾病 (A+F)       0.65      0.71      0.68        21\n",
      "      健康 (C)       0.25      0.20      0.22        10\n",
      "\n",
      "    accuracy                           0.55        31\n",
      "   macro avg       0.45      0.46      0.45        31\n",
      "weighted avg       0.52      0.55      0.53        31\n",
      "\n",
      "ROC AUC: 0.4905\n",
      "\n",
      "測試集結果:\n",
      "Balanced Accuracy: 0.2778\n",
      "混淆矩陣:\n",
      "[[10  8]\n",
      " [ 9  0]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    疾病 (A+F)       0.53      0.56      0.54        18\n",
      "      健康 (C)       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.37        27\n",
      "   macro avg       0.26      0.28      0.27        27\n",
      "weighted avg       0.35      0.37      0.36        27\n",
      "\n",
      "ROC AUC: 0.2778\n",
      "\n",
      "============================================================\n",
      "階層式分類：步驟 2 - AD vs FTD（二分類）\n",
      "============================================================\n",
      "訓練集疾病樣本數: 20\n",
      "驗證集疾病樣本數: 21\n",
      "測試集疾病樣本數: 18\n",
      "\n",
      "疾病樣本分布:\n",
      "訓練集 - A: 12, F: 8\n",
      "驗證集 - A: 13, F: 8\n",
      "測試集 - A: 11, F: 7\n",
      "\n",
      "驗證集結果:\n",
      "Balanced Accuracy: 0.3413\n",
      "混淆矩陣:\n",
      "[[4 9]\n",
      " [5 3]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AD (A)       0.44      0.31      0.36        13\n",
      "     FTD (F)       0.25      0.38      0.30         8\n",
      "\n",
      "    accuracy                           0.33        21\n",
      "   macro avg       0.35      0.34      0.33        21\n",
      "weighted avg       0.37      0.33      0.34        21\n",
      "\n",
      "ROC AUC: 0.4038\n",
      "\n",
      "測試集結果:\n",
      "Balanced Accuracy: 0.7208\n",
      "混淆矩陣:\n",
      "[[8 3]\n",
      " [2 5]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AD (A)       0.80      0.73      0.76        11\n",
      "     FTD (F)       0.62      0.71      0.67         7\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.71      0.72      0.71        18\n",
      "weighted avg       0.73      0.72      0.72        18\n",
      "\n",
      "ROC AUC: 0.7143\n",
      "\n",
      "============================================================\n",
      "階層式分類：最終三分類結果\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Validation Metrics for Hierarchical Classification\n",
      "============================================================\n",
      "\n",
      "Balanced Accuracy: 0.5609\n",
      "\n",
      "混淆矩陣:\n",
      "[[ 4  0  9]\n",
      " [ 0 10  0]\n",
      " [ 5  0  3]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.44      0.31      0.36        13\n",
      "           C       1.00      1.00      1.00        10\n",
      "           F       0.25      0.38      0.30         8\n",
      "\n",
      "    accuracy                           0.55        31\n",
      "   macro avg       0.56      0.56      0.55        31\n",
      "weighted avg       0.57      0.55      0.55        31\n",
      "\n",
      "\n",
      "每個類別的 ROC AUC:\n",
      "  A (Class 0): 0.7906\n",
      "  C (Class 1): 1.0000\n",
      "  F (Class 2): 0.6576\n",
      "\n",
      "宏平均 ROC AUC: 0.8161\n",
      "加權平均 ROC AUC: 0.8238\n",
      "\n",
      "============================================================\n",
      "Test Metrics for Hierarchical Classification\n",
      "============================================================\n",
      "\n",
      "Balanced Accuracy: 0.8139\n",
      "\n",
      "混淆矩陣:\n",
      "[[8 0 3]\n",
      " [0 9 0]\n",
      " [2 0 5]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.80      0.73      0.76        11\n",
      "           C       1.00      1.00      1.00         9\n",
      "           F       0.62      0.71      0.67         7\n",
      "\n",
      "    accuracy                           0.81        27\n",
      "   macro avg       0.81      0.81      0.81        27\n",
      "weighted avg       0.82      0.81      0.82        27\n",
      "\n",
      "\n",
      "每個類別的 ROC AUC:\n",
      "  A (Class 0): 0.7386\n",
      "  C (Class 1): 1.0000\n",
      "  F (Class 2): 0.7929\n",
      "\n",
      "宏平均 ROC AUC: 0.8438\n",
      "加權平均 ROC AUC: 0.8398\n",
      "\n",
      "============================================================\n",
      "過擬合分析\n",
      "============================================================\n",
      "驗證集 Balanced Accuracy: 0.5609\n",
      "測試集 Balanced Accuracy: 0.8139\n",
      "過擬合差距: -0.2530\n",
      "✓ 過擬合程度在可接受範圍內\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "類別預測分布分析\n",
      "============================================================\n",
      "\n",
      "驗證集預測分布:\n",
      "真實分布: {'A': np.int64(13), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "預測分布: {'A': np.int64(9), 'C': np.int64(10), 'F': np.int64(12)}\n",
      "\n",
      "測試集預測分布:\n",
      "真實分布: {'A': np.int64(11), 'C': np.int64(9), 'F': np.int64(7)}\n",
      "預測分布: {'A': np.int64(10), 'C': np.int64(9), 'F': np.int64(8)}\n",
      "============================================================\n",
      "\n",
      "✓ 驗證集預測結果已保存到: ./two_stage_results/logistic_regression/validation_predictions.csv\n",
      "✓ 測試集預測結果已保存到: ./two_stage_results/logistic_regression/test_predictions.csv\n",
      "✓ 評估指標已保存到: ./two_stage_results/logistic_regression/evaluation_metrics.txt\n",
      "✓ 驗證集混淆矩陣已保存到: ./two_stage_results/logistic_regression/confusion_matrix_validation.png\n",
      "✓ 測試集混淆矩陣已保存到: ./two_stage_results/logistic_regression/confusion_matrix_test.png\n",
      "\n",
      "============================================================\n",
      "所有結果已保存完成！\n",
      "============================================================\n",
      "結果目錄: ./two_stage_results/logistic_regression\n",
      "保存的文件:\n",
      "  - validation_predictions.csv (驗證集預測結果)\n",
      "  - test_predictions.csv (測試集預測結果)\n",
      "  - evaluation_metrics.txt (評估指標)\n",
      "  - confusion_matrix_validation.png (驗證集混淆矩陣)\n",
      "  - confusion_matrix_test.png (測試集混淆矩陣)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 完整階層式分類程式（包含資料載入）\n",
    "# ============================================\n",
    "\n",
    "# ============================================\n",
    "# 步驟 0: 資料載入和預處理\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                            balanced_accuracy_score, roc_auc_score,\n",
    "                            roc_curve, auc)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 設置數據路徑\n",
    "base_dir = r'./'\n",
    "dataset_dir = os.path.join(base_dir, 'ds004504')\n",
    "\n",
    "# 讀取特徵數據\n",
    "features_df = pd.read_csv(os.path.join(base_dir, \"features_tv.csv\"))\n",
    "# 讀取參與者信息\n",
    "participants = pd.read_csv(os.path.join(dataset_dir, \"participants.tsv\"), delimiter='\\t')\n",
    "\n",
    "# 合併數據\n",
    "data = features_df.merge(participants, left_index=True, right_index=True)\n",
    "\n",
    "# 定義特徵字典\n",
    "features = {\n",
    "    'stationary_ratio': 'Stationary Ratio',\n",
    "    'Tik-norm': 'Tik-norm',\n",
    "    'Total_Variation': 'Total Variation',\n",
    "    'graph_energy': 'Graph Energy',\n",
    "    'spectral_entropy': 'Spectral Entropy',\n",
    "    'signal_energy': 'Signal Energy',\n",
    "    'signal_power': 'Signal Power',\n",
    "    'avg_degree': 'Average Degree',\n",
    "    'diffusion_distance': 'Diffusion Distance',\n",
    "}\n",
    "\n",
    "# 準備特徵和標籤\n",
    "X = data[list(features.keys())].copy()\n",
    "y = data['Group'].copy()\n",
    "\n",
    "# 數據清理\n",
    "for col in X.columns:\n",
    "    first_val = X[col].iloc[0] if len(X) > 0 else None\n",
    "    if isinstance(first_val, str):\n",
    "        def safe_convert(x):\n",
    "            if pd.isna(x):\n",
    "                return np.nan\n",
    "            if isinstance(x, str):\n",
    "                try:\n",
    "                    parsed = ast.literal_eval(x)\n",
    "                    if isinstance(parsed, (list, tuple, np.ndarray)):\n",
    "                        return float(parsed[0]) if len(parsed) > 0 else np.nan\n",
    "                    return float(parsed)\n",
    "                except:\n",
    "                    try:\n",
    "                        return float(x)\n",
    "                    except:\n",
    "                        try:\n",
    "                            parsed = eval('[' + ','.join(x.strip('[]').split()) + ']')\n",
    "                            return float(parsed[0]) if len(parsed) > 0 else np.nan\n",
    "                        except:\n",
    "                            return np.nan\n",
    "            try:\n",
    "                return float(x) if pd.notna(x) else np.nan\n",
    "            except:\n",
    "                return np.nan\n",
    "        X[col] = X[col].apply(safe_convert)\n",
    "    else:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "rows_with_all_nan = X.isna().all(axis=1)\n",
    "valid_mask = ~(rows_with_all_nan | y.isna())\n",
    "X = X[valid_mask].copy()\n",
    "y = y[valid_mask].copy()\n",
    "\n",
    "if X.isna().sum().sum() > 0:\n",
    "    for col in X.columns:\n",
    "        if X[col].isna().sum() > 0:\n",
    "            median_val = X[col].median()\n",
    "            X[col] = X[col].fillna(median_val)\n",
    "\n",
    "X = X.astype(float)\n",
    "\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"錯誤：清理後數據為空！請檢查原始數據。\")\n",
    "\n",
    "# 數據分割（目標比例：訓練集 30, 驗證集 31, 測試集 27）\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=27/88, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=31/61, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_val = X_val.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# 標準化\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 編碼標籤\n",
    "le = LabelEncoder()\n",
    "y_train_int = le.fit_transform(y_train)\n",
    "y_val_int = le.transform(y_val)\n",
    "y_test_int = le.transform(y_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"數據分割信息\")\n",
    "print(\"=\"*60)\n",
    "print(f\"總樣本數: {len(X)}\")\n",
    "print(f\"訓練集樣本數: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"驗證集樣本數: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"測試集樣本數: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\n類別編碼: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
    "print(f\"訓練集類別分布: {dict(zip(le.classes_, np.bincount(y_train_int)))}\")\n",
    "print(f\"驗證集類別分布: {dict(zip(le.classes_, np.bincount(y_val_int)))}\")\n",
    "print(f\"測試集類別分布: {dict(zip(le.classes_, np.bincount(y_test_int)))}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# 步驟 1：健康 vs 疾病（二分類）\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"階層式分類：步驟 1 - 健康 vs 疾病（二分類）\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_binary_train = (y_train_int == 1).astype(int)  # C=1 是健康，A 和 F 是疾病\n",
    "y_binary_val = (y_val_int == 1).astype(int)\n",
    "y_binary_test = (y_test_int == 1).astype(int)\n",
    "\n",
    "# 訓練二分類模型\n",
    "binary_model = LogisticRegression(C=0.1, class_weight='balanced', random_state=42, max_iter=1000)\n",
    "binary_model.fit(X_train_scaled, y_binary_train)\n",
    "\n",
    "# 驗證集預測\n",
    "binary_val_pred = binary_model.predict(X_val_scaled)\n",
    "binary_val_proba = binary_model.predict_proba(X_val_scaled)\n",
    "\n",
    "# 測試集預測\n",
    "binary_test_pred = binary_model.predict(X_test_scaled)\n",
    "binary_test_proba = binary_model.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"\\n驗證集結果:\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_binary_val, binary_val_pred):.4f}\")\n",
    "print(f\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_binary_val, binary_val_pred))\n",
    "print(f\"\\n分類報告:\")\n",
    "print(classification_report(y_binary_val, binary_val_pred, \n",
    "                            target_names=['疾病 (A+F)', '健康 (C)']))\n",
    "\n",
    "# ROC AUC\n",
    "binary_val_roc = roc_auc_score(y_binary_val, binary_val_proba[:, 1])\n",
    "print(f\"ROC AUC: {binary_val_roc:.4f}\")\n",
    "\n",
    "print(\"\\n測試集結果:\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_binary_test, binary_test_pred):.4f}\")\n",
    "print(f\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_binary_test, binary_test_pred))\n",
    "print(f\"\\n分類報告:\")\n",
    "print(classification_report(y_binary_test, binary_test_pred,\n",
    "                            target_names=['疾病 (A+F)', '健康 (C)']))\n",
    "\n",
    "# ROC AUC\n",
    "binary_test_roc = roc_auc_score(y_binary_test, binary_test_proba[:, 1])\n",
    "print(f\"ROC AUC: {binary_test_roc:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 步驟 2：在疾病樣本中區分 A 和 F\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"階層式分類：步驟 2 - AD vs FTD（二分類）\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "disease_mask_train = y_train_int != 1\n",
    "disease_mask_val = y_val_int != 1\n",
    "disease_mask_test = y_test_int != 1\n",
    "\n",
    "print(f\"訓練集疾病樣本數: {disease_mask_train.sum()}\")\n",
    "print(f\"驗證集疾病樣本數: {disease_mask_val.sum()}\")\n",
    "print(f\"測試集疾病樣本數: {disease_mask_test.sum()}\")\n",
    "\n",
    "if disease_mask_train.sum() > 5 and disease_mask_test.sum() > 3:\n",
    "    # 準備疾病樣本資料\n",
    "    X_disease_train = X_train_scaled[disease_mask_train]\n",
    "    y_disease_train = y_train_int[disease_mask_train]\n",
    "    y_disease_train_binary = (y_disease_train == 2).astype(int)  # A=0, F=1\n",
    "    \n",
    "    X_disease_val = X_val_scaled[disease_mask_val]\n",
    "    y_disease_val = y_val_int[disease_mask_val]\n",
    "    y_disease_val_binary = (y_disease_val == 2).astype(int)\n",
    "    \n",
    "    X_disease_test = X_test_scaled[disease_mask_test]\n",
    "    y_disease_test = y_test_int[disease_mask_test]\n",
    "    y_disease_test_binary = (y_disease_test == 2).astype(int)\n",
    "    \n",
    "    print(f\"\\n疾病樣本分布:\")\n",
    "    print(f\"訓練集 - A: {np.sum(y_disease_train_binary == 0)}, F: {np.sum(y_disease_train_binary == 1)}\")\n",
    "    print(f\"驗證集 - A: {np.sum(y_disease_val_binary == 0)}, F: {np.sum(y_disease_val_binary == 1)}\")\n",
    "    print(f\"測試集 - A: {np.sum(y_disease_test_binary == 0)}, F: {np.sum(y_disease_test_binary == 1)}\")\n",
    "    \n",
    "    # 訓練疾病分類模型\n",
    "    disease_model = LogisticRegression(C=0.1, class_weight='balanced', random_state=42, max_iter=1000)\n",
    "    disease_model.fit(X_disease_train, y_disease_train_binary)\n",
    "    \n",
    "    # 驗證集預測\n",
    "    disease_val_pred = disease_model.predict(X_disease_val)\n",
    "    disease_val_proba = disease_model.predict_proba(X_disease_val)\n",
    "    \n",
    "    # 測試集預測\n",
    "    disease_test_pred = disease_model.predict(X_disease_test)\n",
    "    disease_test_proba = disease_model.predict_proba(X_disease_test)\n",
    "    \n",
    "    print(\"\\n驗證集結果:\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_disease_val_binary, disease_val_pred):.4f}\")\n",
    "    print(f\"混淆矩陣:\")\n",
    "    print(confusion_matrix(y_disease_val_binary, disease_val_pred))\n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_disease_val_binary, disease_val_pred,\n",
    "                                target_names=['AD (A)', 'FTD (F)']))\n",
    "    \n",
    "    # ROC AUC\n",
    "    if len(np.unique(y_disease_val_binary)) > 1:\n",
    "        disease_val_roc = roc_auc_score(y_disease_val_binary, disease_val_proba[:, 1])\n",
    "        print(f\"ROC AUC: {disease_val_roc:.4f}\")\n",
    "    \n",
    "    print(\"\\n測試集結果:\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_disease_test_binary, disease_test_pred):.4f}\")\n",
    "    print(f\"混淆矩陣:\")\n",
    "    print(confusion_matrix(y_disease_test_binary, disease_test_pred))\n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_disease_test_binary, disease_test_pred,\n",
    "                                target_names=['AD (A)', 'FTD (F)']))\n",
    "    \n",
    "    # ROC AUC\n",
    "    if len(np.unique(y_disease_test_binary)) > 1:\n",
    "        disease_test_roc = roc_auc_score(y_disease_test_binary, disease_test_proba[:, 1])\n",
    "        print(f\"ROC AUC: {disease_test_roc:.4f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 步驟 3：組合預測（三分類最終結果）\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"階層式分類：最終三分類結果\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 驗證集組合預測\n",
    "    final_val_pred = np.zeros(len(y_val_int))\n",
    "    final_val_pred[y_binary_val == 1] = 1  # 健康 = C (1)\n",
    "    disease_val_indices = np.where(y_binary_val == 0)[0]\n",
    "    # 如果預測為疾病，則使用疾病分類器的預測：A=0, F=2\n",
    "    final_val_pred[disease_val_indices] = disease_val_pred * 2\n",
    "    \n",
    "    # 測試集組合預測\n",
    "    final_test_pred = np.zeros(len(y_test_int))\n",
    "    final_test_pred[y_binary_test == 1] = 1  # 健康 = C (1)\n",
    "    disease_test_indices = np.where(y_binary_test == 0)[0]\n",
    "    # 如果預測為疾病，則使用疾病分類器的預測：A=0, F=2\n",
    "    final_test_pred[disease_test_indices] = disease_test_pred * 2\n",
    "    \n",
    "    # ============================================\n",
    "    # 驗證集完整評估\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Validation Metrics for Hierarchical Classification\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    val_balanced_acc = balanced_accuracy_score(y_val_int, final_val_pred.astype(int))\n",
    "    print(f\"\\nBalanced Accuracy: {val_balanced_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\n混淆矩陣:\")\n",
    "    print(confusion_matrix(y_val_int, final_val_pred.astype(int)))\n",
    "    \n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_val_int, final_val_pred.astype(int), \n",
    "                                target_names=list(le.classes_)))\n",
    "    \n",
    "    # 計算每個類別的預測概率（用於 ROC AUC）\n",
    "    final_val_proba = np.zeros((len(y_val_int), 3))\n",
    "    \n",
    "    # 健康類別（C）的概率\n",
    "    final_val_proba[:, 1] = binary_val_proba[:, 1]\n",
    "    \n",
    "    # 疾病類別的概率 = P(疾病) * P(具體疾病類型|疾病)\n",
    "    disease_prob = binary_val_proba[:, 0]  # P(疾病)\n",
    "    final_val_proba[disease_val_indices, 0] = disease_prob[disease_val_indices] * disease_val_proba[:, 0]  # A\n",
    "    final_val_proba[disease_val_indices, 2] = disease_prob[disease_val_indices] * disease_val_proba[:, 1]  # F\n",
    "    \n",
    "    # 歸一化概率\n",
    "    final_val_proba = final_val_proba / (final_val_proba.sum(axis=1, keepdims=True) + 1e-10)\n",
    "    \n",
    "    # ROC AUC\n",
    "    val_binarized = label_binarize(y_val_int, classes=[0, 1, 2])\n",
    "    print(\"\\n每個類別的 ROC AUC:\")\n",
    "    for i, class_name in enumerate(le.classes_):\n",
    "        fpr, tpr, _ = roc_curve(val_binarized[:, i], final_val_proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(f\"  {class_name} (Class {i}): {roc_auc:.4f}\")\n",
    "    \n",
    "    macro_roc_auc_val = roc_auc_score(y_val_int, final_val_proba, multi_class='ovr', average='macro')\n",
    "    weighted_roc_auc_val = roc_auc_score(y_val_int, final_val_proba, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    print(f\"\\n宏平均 ROC AUC: {macro_roc_auc_val:.4f}\")\n",
    "    print(f\"加權平均 ROC AUC: {weighted_roc_auc_val:.4f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 測試集完整評估\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Test Metrics for Hierarchical Classification\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_balanced_acc = balanced_accuracy_score(y_test_int, final_test_pred.astype(int))\n",
    "    print(f\"\\nBalanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\n混淆矩陣:\")\n",
    "    print(confusion_matrix(y_test_int, final_test_pred.astype(int)))\n",
    "    \n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_test_int, final_test_pred.astype(int),\n",
    "                                target_names=list(le.classes_)))\n",
    "    \n",
    "    # 計算測試集概率\n",
    "    final_test_proba = np.zeros((len(y_test_int), 3))\n",
    "    final_test_proba[:, 1] = binary_test_proba[:, 1]  # 健康類別\n",
    "    disease_prob_test = binary_test_proba[:, 0]\n",
    "    final_test_proba[disease_test_indices, 0] = disease_prob_test[disease_test_indices] * disease_test_proba[:, 0]\n",
    "    final_test_proba[disease_test_indices, 2] = disease_prob_test[disease_test_indices] * disease_test_proba[:, 1]\n",
    "    final_test_proba = final_test_proba / (final_test_proba.sum(axis=1, keepdims=True) + 1e-10)\n",
    "    \n",
    "    # ROC AUC\n",
    "    test_binarized = label_binarize(y_test_int, classes=[0, 1, 2])\n",
    "    print(\"\\n每個類別的 ROC AUC:\")\n",
    "    for i, class_name in enumerate(le.classes_):\n",
    "        fpr, tpr, _ = roc_curve(test_binarized[:, i], final_test_proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(f\"  {class_name} (Class {i}): {roc_auc:.4f}\")\n",
    "    \n",
    "    macro_roc_auc_test = roc_auc_score(y_test_int, final_test_proba, multi_class='ovr', average='macro')\n",
    "    weighted_roc_auc_test = roc_auc_score(y_test_int, final_test_proba, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    print(f\"\\n宏平均 ROC AUC: {macro_roc_auc_test:.4f}\")\n",
    "    print(f\"加權平均 ROC AUC: {weighted_roc_auc_test:.4f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 過擬合分析\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"過擬合分析\")\n",
    "    print(\"=\"*60)\n",
    "    overfitting_gap = val_balanced_acc - test_balanced_acc\n",
    "    print(f\"驗證集 Balanced Accuracy: {val_balanced_acc:.4f}\")\n",
    "    print(f\"測試集 Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "    print(f\"過擬合差距: {overfitting_gap:.4f}\")\n",
    "    \n",
    "    if overfitting_gap > 0.15:\n",
    "        print(\"⚠️ 警告：存在明顯過擬合（差距 > 0.15）\")\n",
    "    elif overfitting_gap > 0.10:\n",
    "        print(\"⚠️ 注意：存在一定過擬合（差距 > 0.10）\")\n",
    "    else:\n",
    "        print(\"✓ 過擬合程度在可接受範圍內\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ============================================\n",
    "    # 類別預測分布分析\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"類別預測分布分析\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n驗證集預測分布:\")\n",
    "    val_pred_counts = {le.classes_[i]: np.sum(final_val_pred.astype(int) == i) for i in range(len(le.classes_))}\n",
    "    val_true_counts = {le.classes_[i]: np.sum(y_val_int == i) for i in range(len(le.classes_))}\n",
    "    print(f\"真實分布: {val_true_counts}\")\n",
    "    print(f\"預測分布: {val_pred_counts}\")\n",
    "    \n",
    "    print(\"\\n測試集預測分布:\")\n",
    "    test_pred_counts = {le.classes_[i]: np.sum(final_test_pred.astype(int) == i) for i in range(len(le.classes_))}\n",
    "    test_true_counts = {le.classes_[i]: np.sum(y_test_int == i) for i in range(len(le.classes_))}\n",
    "    print(f\"真實分布: {test_true_counts}\")\n",
    "    print(f\"預測分布: {test_pred_counts}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ 警告：疾病樣本數量不足，無法進行第二步分類\")\n",
    "    print(\"只進行健康 vs 疾病的分類\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 保存結果和繪製 Confusion Matrix\n",
    "# ============================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# 創建結果目錄\n",
    "results_dir = './two_stage_results/logistic_regression'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 保存預測結果到 CSV\n",
    "if disease_mask_train.sum() > 5 and disease_mask_test.sum() > 3:\n",
    "    # 驗證集結果\n",
    "    val_results_df = pd.DataFrame({\n",
    "        'true_label': [le.classes_[i] for i in y_val_int],\n",
    "        'predicted_label': [le.classes_[int(i)] for i in final_val_pred],\n",
    "        'true_label_int': y_val_int,\n",
    "        'predicted_label_int': final_val_pred.astype(int),\n",
    "        'prob_A': final_val_proba[:, 0],\n",
    "        'prob_C': final_val_proba[:, 1],\n",
    "        'prob_F': final_val_proba[:, 2]\n",
    "    })\n",
    "    val_results_df.to_csv(os.path.join(results_dir, 'validation_predictions.csv'), index=False)\n",
    "    print(f\"\\n✓ 驗證集預測結果已保存到: {os.path.join(results_dir, 'validation_predictions.csv')}\")\n",
    "    \n",
    "    # 測試集結果\n",
    "    test_results_df = pd.DataFrame({\n",
    "        'true_label': [le.classes_[i] for i in y_test_int],\n",
    "        'predicted_label': [le.classes_[int(i)] for i in final_test_pred],\n",
    "        'true_label_int': y_test_int,\n",
    "        'predicted_label_int': final_test_pred.astype(int),\n",
    "        'prob_A': final_test_proba[:, 0],\n",
    "        'prob_C': final_test_proba[:, 1],\n",
    "        'prob_F': final_test_proba[:, 2]\n",
    "    })\n",
    "    test_results_df.to_csv(os.path.join(results_dir, 'test_predictions.csv'), index=False)\n",
    "    print(f\"✓ 測試集預測結果已保存到: {os.path.join(results_dir, 'test_predictions.csv')}\")\n",
    "    \n",
    "    # 保存評估指標到文本文件\n",
    "    with open(os.path.join(results_dir, 'evaluation_metrics.txt'), 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"階層式分類評估結果\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(f\"生成時間: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"驗證集結果:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {val_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"宏平均 ROC AUC: {macro_roc_auc_val:.4f}\\n\")\n",
    "        f.write(f\"加權平均 ROC AUC: {weighted_roc_auc_val:.4f}\\n\\n\")\n",
    "        f.write(\"混淆矩陣:\\n\")\n",
    "        f.write(str(confusion_matrix(y_val_int, final_val_pred.astype(int))) + \"\\n\\n\")\n",
    "        f.write(\"分類報告:\\n\")\n",
    "        f.write(classification_report(y_val_int, final_val_pred.astype(int), \n",
    "                                     target_names=list(le.classes_)) + \"\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"測試集結果:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {test_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"宏平均 ROC AUC: {macro_roc_auc_test:.4f}\\n\")\n",
    "        f.write(f\"加權平均 ROC AUC: {weighted_roc_auc_test:.4f}\\n\\n\")\n",
    "        f.write(\"混淆矩陣:\\n\")\n",
    "        f.write(str(confusion_matrix(y_test_int, final_test_pred.astype(int))) + \"\\n\\n\")\n",
    "        f.write(\"分類報告:\\n\")\n",
    "        f.write(classification_report(y_test_int, final_test_pred.astype(int),\n",
    "                                     target_names=list(le.classes_)) + \"\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"過擬合分析:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"驗證集 Balanced Accuracy: {val_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"測試集 Balanced Accuracy: {test_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"過擬合差距: {overfitting_gap:.4f}\\n\")\n",
    "    \n",
    "    print(f\"✓ 評估指標已保存到: {os.path.join(results_dir, 'evaluation_metrics.txt')}\")\n",
    "    \n",
    "    # 繪製 Confusion Matrix\n",
    "    class_names = list(le.classes_)\n",
    "    \n",
    "    # 驗證集 Confusion Matrix\n",
    "    cm_val = confusion_matrix(y_val_int, final_val_pred.astype(int))\n",
    "    cm_val_normalized = cm_val.astype('float') / (cm_val.sum(axis=1)[:, np.newaxis] + 1e-10)\n",
    "    cm_val_normalized = np.nan_to_num(cm_val_normalized)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 原始混淆矩陣\n",
    "    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "    axes[0].set_title('Validation Set Confusion Matrix (Count)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[0].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    \n",
    "    # 歸一化混淆矩陣\n",
    "    sns.heatmap(cm_val_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[1], cbar_kws={'label': 'Percentage'})\n",
    "    axes[1].set_title('Validation Set Confusion Matrix (Percentage)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[1].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    val_cm_path = os.path.join(results_dir, 'confusion_matrix_validation.png')\n",
    "    plt.savefig(val_cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ 驗證集混淆矩陣已保存到: {val_cm_path}\")\n",
    "    \n",
    "    # 測試集 Confusion Matrix\n",
    "    cm_test = confusion_matrix(y_test_int, final_test_pred.astype(int))\n",
    "    cm_test_normalized = cm_test.astype('float') / (cm_test.sum(axis=1)[:, np.newaxis] + 1e-10)\n",
    "    cm_test_normalized = np.nan_to_num(cm_test_normalized)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 原始混淆矩陣\n",
    "    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "    axes[0].set_title('Test Set Confusion Matrix (Count)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[0].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    # 歸一化混淆矩陣\n",
    "    sns.heatmap(cm_test_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[1], cbar_kws={'label': 'Percentage'})\n",
    "    axes[1].set_title('Test Set Confusion Matrix (Percentage)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[1].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    test_cm_path = os.path.join(results_dir, 'confusion_matrix_test.png')\n",
    "    plt.savefig(test_cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ 測試集混淆矩陣已保存到: {test_cm_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"所有結果已保存完成！\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"結果目錄: {results_dir}\")\n",
    "    print(\"保存的文件:\")\n",
    "    print(\"  - validation_predictions.csv (驗證集預測結果)\")\n",
    "    print(\"  - test_predictions.csv (測試集預測結果)\")\n",
    "    print(\"  - evaluation_metrics.txt (評估指標)\")\n",
    "    print(\"  - confusion_matrix_validation.png (驗證集混淆矩陣)\")\n",
    "    print(\"  - confusion_matrix_test.png (測試集混淆矩陣)\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    # 如果只有二分類結果，也保存\n",
    "    val_results_df = pd.DataFrame({\n",
    "        'true_label': ['疾病 (A+F)' if i == 0 else '健康 (C)' for i in y_binary_val],\n",
    "        'predicted_label': ['疾病 (A+F)' if i == 0 else '健康 (C)' for i in binary_val_pred],\n",
    "        'true_label_int': y_binary_val,\n",
    "        'predicted_label_int': binary_val_pred,\n",
    "        'prob_disease': binary_val_proba[:, 0],\n",
    "        'prob_healthy': binary_val_proba[:, 1]\n",
    "    })\n",
    "    val_results_df.to_csv(os.path.join(results_dir, 'validation_predictions_binary.csv'), index=False)\n",
    "    \n",
    "    test_results_df = pd.DataFrame({\n",
    "        'true_label': ['疾病 (A+F)' if i == 0 else '健康 (C)' for i in y_binary_test],\n",
    "        'predicted_label': ['疾病 (A+F)' if i == 0 else '健康 (C)' for i in binary_test_pred],\n",
    "        'true_label_int': y_binary_test,\n",
    "        'predicted_label_int': binary_test_pred,\n",
    "        'prob_disease': binary_test_proba[:, 0],\n",
    "        'prob_healthy': binary_test_proba[:, 1]\n",
    "    })\n",
    "    test_results_df.to_csv(os.path.join(results_dir, 'test_predictions_binary.csv'), index=False)\n",
    "    \n",
    "    print(f\"\\n✓ 二分類結果已保存到: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf49fd7",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd428cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "數據分割信息\n",
      "============================================================\n",
      "總樣本數: 88\n",
      "訓練集樣本數: 30 (34.1%)\n",
      "驗證集樣本數: 31 (35.2%)\n",
      "測試集樣本數: 27 (30.7%)\n",
      "\n",
      "類別編碼: {'A': 0, 'C': 1, 'F': 2}\n",
      "訓練集類別分布: {'A': np.int64(12), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "驗證集類別分布: {'A': np.int64(13), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "測試集類別分布: {'A': np.int64(11), 'C': np.int64(9), 'F': np.int64(7)}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "階層式分類：步驟 1 - 健康 vs 疾病（二分類）- 使用 SVM\n",
      "============================================================\n",
      "\n",
      "驗證集結果:\n",
      "Balanced Accuracy: 0.4548\n",
      "混淆矩陣:\n",
      "[[17  4]\n",
      " [ 9  1]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    疾病 (A+F)       0.65      0.81      0.72        21\n",
      "      健康 (C)       0.20      0.10      0.13        10\n",
      "\n",
      "    accuracy                           0.58        31\n",
      "   macro avg       0.43      0.45      0.43        31\n",
      "weighted avg       0.51      0.58      0.53        31\n",
      "\n",
      "ROC AUC: 0.6143\n",
      "\n",
      "測試集結果:\n",
      "Balanced Accuracy: 0.3611\n",
      "混淆矩陣:\n",
      "[[13  5]\n",
      " [ 9  0]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    疾病 (A+F)       0.59      0.72      0.65        18\n",
      "      健康 (C)       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.48        27\n",
      "   macro avg       0.30      0.36      0.33        27\n",
      "weighted avg       0.39      0.48      0.43        27\n",
      "\n",
      "ROC AUC: 0.6975\n",
      "\n",
      "============================================================\n",
      "階層式分類：步驟 2 - AD vs FTD（二分類）- 使用 SVM\n",
      "============================================================\n",
      "訓練集疾病樣本數: 20\n",
      "驗證集疾病樣本數: 21\n",
      "測試集疾病樣本數: 18\n",
      "\n",
      "疾病樣本分布:\n",
      "訓練集 - A: 12, F: 8\n",
      "驗證集 - A: 13, F: 8\n",
      "測試集 - A: 11, F: 7\n",
      "\n",
      "驗證集結果:\n",
      "Balanced Accuracy: 0.6731\n",
      "混淆矩陣:\n",
      "[[11  2]\n",
      " [ 4  4]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AD (A)       0.73      0.85      0.79        13\n",
      "     FTD (F)       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.70      0.67      0.68        21\n",
      "weighted avg       0.71      0.71      0.70        21\n",
      "\n",
      "ROC AUC: 0.3077\n",
      "\n",
      "測試集結果:\n",
      "Balanced Accuracy: 0.5584\n",
      "混淆矩陣:\n",
      "[[6 5]\n",
      " [3 4]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AD (A)       0.67      0.55      0.60        11\n",
      "     FTD (F)       0.44      0.57      0.50         7\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.56      0.56      0.55        18\n",
      "weighted avg       0.58      0.56      0.56        18\n",
      "\n",
      "ROC AUC: 0.4026\n",
      "\n",
      "============================================================\n",
      "階層式分類：最終三分類結果（使用 SVM）\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Validation Metrics for Hierarchical Classification (SVM)\n",
      "============================================================\n",
      "\n",
      "Balanced Accuracy: 0.7821\n",
      "\n",
      "混淆矩陣:\n",
      "[[11  0  2]\n",
      " [ 0 10  0]\n",
      " [ 4  0  4]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.73      0.85      0.79        13\n",
      "           C       1.00      1.00      1.00        10\n",
      "           F       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.80      0.78      0.79        31\n",
      "weighted avg       0.80      0.81      0.80        31\n",
      "\n",
      "\n",
      "每個類別的 ROC AUC:\n",
      "  A (Class 0): 0.7009\n",
      "  C (Class 1): 1.0000\n",
      "  F (Class 2): 0.6957\n",
      "\n",
      "宏平均 ROC AUC: 0.7988\n",
      "加權平均 ROC AUC: 0.7960\n",
      "\n",
      "============================================================\n",
      "Test Metrics for Hierarchical Classification (SVM)\n",
      "============================================================\n",
      "\n",
      "Balanced Accuracy: 0.7056\n",
      "\n",
      "混淆矩陣:\n",
      "[[6 0 5]\n",
      " [0 9 0]\n",
      " [3 0 4]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.67      0.55      0.60        11\n",
      "           C       1.00      1.00      1.00         9\n",
      "           F       0.44      0.57      0.50         7\n",
      "\n",
      "    accuracy                           0.70        27\n",
      "   macro avg       0.70      0.71      0.70        27\n",
      "weighted avg       0.72      0.70      0.71        27\n",
      "\n",
      "\n",
      "每個類別的 ROC AUC:\n",
      "  A (Class 0): 0.8011\n",
      "  C (Class 1): 1.0000\n",
      "  F (Class 2): 0.6214\n",
      "\n",
      "宏平均 ROC AUC: 0.8075\n",
      "加權平均 ROC AUC: 0.8208\n",
      "\n",
      "============================================================\n",
      "過擬合分析\n",
      "============================================================\n",
      "驗證集 Balanced Accuracy: 0.7821\n",
      "測試集 Balanced Accuracy: 0.7056\n",
      "過擬合差距: 0.0764\n",
      "✓ 過擬合程度在可接受範圍內\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "類別預測分布分析\n",
      "============================================================\n",
      "\n",
      "驗證集預測分布:\n",
      "真實分布: {'A': np.int64(13), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "預測分布: {'A': np.int64(15), 'C': np.int64(10), 'F': np.int64(6)}\n",
      "\n",
      "測試集預測分布:\n",
      "真實分布: {'A': np.int64(11), 'C': np.int64(9), 'F': np.int64(7)}\n",
      "預測分布: {'A': np.int64(9), 'C': np.int64(9), 'F': np.int64(9)}\n",
      "============================================================\n",
      "\n",
      "✓ 驗證集預測結果已保存到: ./two_stage_results/SVM/validation_predictions.csv\n",
      "✓ 測試集預測結果已保存到: ./two_stage_results/SVM/test_predictions.csv\n",
      "✓ 評估指標已保存到: ./two_stage_results/SVM/evaluation_metrics.txt\n",
      "✓ 驗證集混淆矩陣已保存到: ./two_stage_results/SVM/confusion_matrix_validation.png\n",
      "✓ 測試集混淆矩陣已保存到: ./two_stage_results/SVM/confusion_matrix_test.png\n",
      "\n",
      "============================================================\n",
      "所有結果已保存完成！\n",
      "============================================================\n",
      "結果目錄: ./two_stage_results/SVM\n",
      "保存的文件:\n",
      "  - validation_predictions.csv (驗證集預測結果)\n",
      "  - test_predictions.csv (測試集預測結果)\n",
      "  - evaluation_metrics.txt (評估指標)\n",
      "  - confusion_matrix_validation.png (驗證集混淆矩陣)\n",
      "  - confusion_matrix_test.png (測試集混淆矩陣)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 完整階層式分類程式（使用 SVM）\n",
    "# ============================================\n",
    "\n",
    "# ============================================\n",
    "# 步驟 0: 資料載入和預處理\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                            balanced_accuracy_score, roc_auc_score,\n",
    "                            roc_curve, auc)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.svm import SVC\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 設置數據路徑\n",
    "base_dir = r''\n",
    "dataset_dir = os.path.join(base_dir, 'ds004504')\n",
    "\n",
    "# 讀取特徵數據\n",
    "features_df = pd.read_csv(os.path.join(base_dir, \"features_tv.csv\"))\n",
    "# 讀取參與者信息\n",
    "participants = pd.read_csv(os.path.join(dataset_dir, \"participants.tsv\"), delimiter='\\t')\n",
    "\n",
    "# 合併數據\n",
    "data = features_df.merge(participants, left_index=True, right_index=True)\n",
    "\n",
    "# 定義特徵字典\n",
    "features = {\n",
    "    'stationary_ratio': 'Stationary Ratio',\n",
    "    'Tik-norm': 'Tik-norm',\n",
    "    'Total_Variation': 'Total Variation',\n",
    "    'graph_energy': 'Graph Energy',\n",
    "    'spectral_entropy': 'Spectral Entropy',\n",
    "    'signal_energy': 'Signal Energy',\n",
    "    'signal_power': 'Signal Power',\n",
    "    'avg_degree': 'Average Degree',\n",
    "    'diffusion_distance': 'Diffusion Distance',\n",
    "}\n",
    "\n",
    "# 準備特徵和標籤\n",
    "X = data[list(features.keys())].copy()\n",
    "y = data['Group'].copy()\n",
    "\n",
    "# 數據清理\n",
    "for col in X.columns:\n",
    "    first_val = X[col].iloc[0] if len(X) > 0 else None\n",
    "    if isinstance(first_val, str):\n",
    "        def safe_convert(x):\n",
    "            if pd.isna(x):\n",
    "                return np.nan\n",
    "            if isinstance(x, str):\n",
    "                try:\n",
    "                    parsed = ast.literal_eval(x)\n",
    "                    if isinstance(parsed, (list, tuple, np.ndarray)):\n",
    "                        return float(parsed[0]) if len(parsed) > 0 else np.nan\n",
    "                    return float(parsed)\n",
    "                except:\n",
    "                    try:\n",
    "                        return float(x)\n",
    "                    except:\n",
    "                        try:\n",
    "                            parsed = eval('[' + ','.join(x.strip('[]').split()) + ']')\n",
    "                            return float(parsed[0]) if len(parsed) > 0 else np.nan\n",
    "                        except:\n",
    "                            return np.nan\n",
    "            try:\n",
    "                return float(x) if pd.notna(x) else np.nan\n",
    "            except:\n",
    "                return np.nan\n",
    "        X[col] = X[col].apply(safe_convert)\n",
    "    else:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "rows_with_all_nan = X.isna().all(axis=1)\n",
    "valid_mask = ~(rows_with_all_nan | y.isna())\n",
    "X = X[valid_mask].copy()\n",
    "y = y[valid_mask].copy()\n",
    "\n",
    "if X.isna().sum().sum() > 0:\n",
    "    for col in X.columns:\n",
    "        if X[col].isna().sum() > 0:\n",
    "            median_val = X[col].median()\n",
    "            X[col] = X[col].fillna(median_val)\n",
    "\n",
    "X = X.astype(float)\n",
    "\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"錯誤：清理後數據為空！請檢查原始數據。\")\n",
    "\n",
    "# 數據分割（目標比例：訓練集 30, 驗證集 31, 測試集 27）\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=27/88, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=31/61, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_val = X_val.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# 標準化\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 編碼標籤\n",
    "le = LabelEncoder()\n",
    "y_train_int = le.fit_transform(y_train)\n",
    "y_val_int = le.transform(y_val)\n",
    "y_test_int = le.transform(y_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"數據分割信息\")\n",
    "print(\"=\"*60)\n",
    "print(f\"總樣本數: {len(X)}\")\n",
    "print(f\"訓練集樣本數: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"驗證集樣本數: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"測試集樣本數: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\n類別編碼: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
    "print(f\"訓練集類別分布: {dict(zip(le.classes_, np.bincount(y_train_int)))}\")\n",
    "print(f\"驗證集類別分布: {dict(zip(le.classes_, np.bincount(y_val_int)))}\")\n",
    "print(f\"測試集類別分布: {dict(zip(le.classes_, np.bincount(y_test_int)))}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# 步驟 1：健康 vs 疾病（二分類）- 使用 SVM\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"階層式分類：步驟 1 - 健康 vs 疾病（二分類）- 使用 SVM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_binary_train = (y_train_int == 1).astype(int)  # C=1 是健康，A 和 F 是疾病\n",
    "y_binary_val = (y_val_int == 1).astype(int)\n",
    "y_binary_test = (y_test_int == 1).astype(int)\n",
    "\n",
    "# 訓練 SVM 二分類模型\n",
    "binary_model = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,  # 正則化參數，可以調整\n",
    "    gamma='scale',  # RBF 核的參數\n",
    "    class_weight='balanced',  # 處理類別不平衡\n",
    "    probability=True,  # 需要概率輸出用於 ROC AUC\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "binary_model.fit(X_train_scaled, y_binary_train)\n",
    "\n",
    "# 驗證集預測\n",
    "binary_val_pred = binary_model.predict(X_val_scaled)\n",
    "binary_val_proba = binary_model.predict_proba(X_val_scaled)\n",
    "\n",
    "# 測試集預測\n",
    "binary_test_pred = binary_model.predict(X_test_scaled)\n",
    "binary_test_proba = binary_model.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"\\n驗證集結果:\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_binary_val, binary_val_pred):.4f}\")\n",
    "print(f\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_binary_val, binary_val_pred))\n",
    "print(f\"\\n分類報告:\")\n",
    "print(classification_report(y_binary_val, binary_val_pred, \n",
    "                            target_names=['疾病 (A+F)', '健康 (C)']))\n",
    "\n",
    "# ROC AUC\n",
    "binary_val_roc = roc_auc_score(y_binary_val, binary_val_proba[:, 1])\n",
    "print(f\"ROC AUC: {binary_val_roc:.4f}\")\n",
    "\n",
    "print(\"\\n測試集結果:\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_binary_test, binary_test_pred):.4f}\")\n",
    "print(f\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_binary_test, binary_test_pred))\n",
    "print(f\"\\n分類報告:\")\n",
    "print(classification_report(y_binary_test, binary_test_pred,\n",
    "                            target_names=['疾病 (A+F)', '健康 (C)']))\n",
    "\n",
    "# ROC AUC\n",
    "binary_test_roc = roc_auc_score(y_binary_test, binary_test_proba[:, 1])\n",
    "print(f\"ROC AUC: {binary_test_roc:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 步驟 2：在疾病樣本中區分 A 和 F - 使用 SVM\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"階層式分類：步驟 2 - AD vs FTD（二分類）- 使用 SVM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "disease_mask_train = y_train_int != 1\n",
    "disease_mask_val = y_val_int != 1\n",
    "disease_mask_test = y_test_int != 1\n",
    "\n",
    "print(f\"訓練集疾病樣本數: {disease_mask_train.sum()}\")\n",
    "print(f\"驗證集疾病樣本數: {disease_mask_val.sum()}\")\n",
    "print(f\"測試集疾病樣本數: {disease_mask_test.sum()}\")\n",
    "\n",
    "if disease_mask_train.sum() > 5 and disease_mask_test.sum() > 3:\n",
    "    # 準備疾病樣本資料\n",
    "    X_disease_train = X_train_scaled[disease_mask_train]\n",
    "    y_disease_train = y_train_int[disease_mask_train]\n",
    "    y_disease_train_binary = (y_disease_train == 2).astype(int)  # A=0, F=1\n",
    "    \n",
    "    X_disease_val = X_val_scaled[disease_mask_val]\n",
    "    y_disease_val = y_val_int[disease_mask_val]\n",
    "    y_disease_val_binary = (y_disease_val == 2).astype(int)\n",
    "    \n",
    "    X_disease_test = X_test_scaled[disease_mask_test]\n",
    "    y_disease_test = y_test_int[disease_mask_test]\n",
    "    y_disease_test_binary = (y_disease_test == 2).astype(int)\n",
    "    \n",
    "    print(f\"\\n疾病樣本分布:\")\n",
    "    print(f\"訓練集 - A: {np.sum(y_disease_train_binary == 0)}, F: {np.sum(y_disease_train_binary == 1)}\")\n",
    "    print(f\"驗證集 - A: {np.sum(y_disease_val_binary == 0)}, F: {np.sum(y_disease_val_binary == 1)}\")\n",
    "    print(f\"測試集 - A: {np.sum(y_disease_test_binary == 0)}, F: {np.sum(y_disease_test_binary == 1)}\")\n",
    "    \n",
    "    # 訓練 SVM 疾病分類模型\n",
    "    disease_model = SVC(\n",
    "        kernel='rbf',\n",
    "        C=1.0,\n",
    "        gamma='scale',\n",
    "        class_weight='balanced',\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    disease_model.fit(X_disease_train, y_disease_train_binary)\n",
    "    \n",
    "    # 驗證集預測\n",
    "    disease_val_pred = disease_model.predict(X_disease_val)\n",
    "    disease_val_proba = disease_model.predict_proba(X_disease_val)\n",
    "    \n",
    "    # 測試集預測\n",
    "    disease_test_pred = disease_model.predict(X_disease_test)\n",
    "    disease_test_proba = disease_model.predict_proba(X_disease_test)\n",
    "    \n",
    "    print(\"\\n驗證集結果:\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_disease_val_binary, disease_val_pred):.4f}\")\n",
    "    print(f\"混淆矩陣:\")\n",
    "    print(confusion_matrix(y_disease_val_binary, disease_val_pred))\n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_disease_val_binary, disease_val_pred,\n",
    "                                target_names=['AD (A)', 'FTD (F)']))\n",
    "    \n",
    "    # ROC AUC\n",
    "    if len(np.unique(y_disease_val_binary)) > 1:\n",
    "        disease_val_roc = roc_auc_score(y_disease_val_binary, disease_val_proba[:, 1])\n",
    "        print(f\"ROC AUC: {disease_val_roc:.4f}\")\n",
    "    \n",
    "    print(\"\\n測試集結果:\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_disease_test_binary, disease_test_pred):.4f}\")\n",
    "    print(f\"混淆矩陣:\")\n",
    "    print(confusion_matrix(y_disease_test_binary, disease_test_pred))\n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_disease_test_binary, disease_test_pred,\n",
    "                                target_names=['AD (A)', 'FTD (F)']))\n",
    "    \n",
    "    # ROC AUC\n",
    "    if len(np.unique(y_disease_test_binary)) > 1:\n",
    "        disease_test_roc = roc_auc_score(y_disease_test_binary, disease_test_proba[:, 1])\n",
    "        print(f\"ROC AUC: {disease_test_roc:.4f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 步驟 3：組合預測（三分類最終結果）\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"階層式分類：最終三分類結果（使用 SVM）\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 驗證集組合預測\n",
    "    final_val_pred = np.zeros(len(y_val_int))\n",
    "    final_val_pred[y_binary_val == 1] = 1  # 健康 = C (1)\n",
    "    disease_val_indices = np.where(y_binary_val == 0)[0]\n",
    "    # 如果預測為疾病，則使用疾病分類器的預測：A=0, F=2\n",
    "    final_val_pred[disease_val_indices] = disease_val_pred * 2\n",
    "    \n",
    "    # 測試集組合預測\n",
    "    final_test_pred = np.zeros(len(y_test_int))\n",
    "    final_test_pred[y_binary_test == 1] = 1  # 健康 = C (1)\n",
    "    disease_test_indices = np.where(y_binary_test == 0)[0]\n",
    "    # 如果預測為疾病，則使用疾病分類器的預測：A=0, F=2\n",
    "    final_test_pred[disease_test_indices] = disease_test_pred * 2\n",
    "    \n",
    "    # ============================================\n",
    "    # 驗證集完整評估\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Validation Metrics for Hierarchical Classification (SVM)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    val_balanced_acc = balanced_accuracy_score(y_val_int, final_val_pred.astype(int))\n",
    "    print(f\"\\nBalanced Accuracy: {val_balanced_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\n混淆矩陣:\")\n",
    "    print(confusion_matrix(y_val_int, final_val_pred.astype(int)))\n",
    "    \n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_val_int, final_val_pred.astype(int), \n",
    "                                target_names=list(le.classes_)))\n",
    "    \n",
    "    # 計算每個類別的預測概率（用於 ROC AUC）\n",
    "    final_val_proba = np.zeros((len(y_val_int), 3))\n",
    "    \n",
    "    # 健康類別（C）的概率\n",
    "    final_val_proba[:, 1] = binary_val_proba[:, 1]\n",
    "    \n",
    "    # 疾病類別的概率 = P(疾病) * P(具體疾病類型|疾病)\n",
    "    disease_prob = binary_val_proba[:, 0]  # P(疾病)\n",
    "    final_val_proba[disease_val_indices, 0] = disease_prob[disease_val_indices] * disease_val_proba[:, 0]  # A\n",
    "    final_val_proba[disease_val_indices, 2] = disease_prob[disease_val_indices] * disease_val_proba[:, 1]  # F\n",
    "    \n",
    "    # 歸一化概率\n",
    "    final_val_proba = final_val_proba / (final_val_proba.sum(axis=1, keepdims=True) + 1e-10)\n",
    "    \n",
    "    # ROC AUC\n",
    "    val_binarized = label_binarize(y_val_int, classes=[0, 1, 2])\n",
    "    print(\"\\n每個類別的 ROC AUC:\")\n",
    "    for i, class_name in enumerate(le.classes_):\n",
    "        fpr, tpr, _ = roc_curve(val_binarized[:, i], final_val_proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(f\"  {class_name} (Class {i}): {roc_auc:.4f}\")\n",
    "    \n",
    "    macro_roc_auc_val = roc_auc_score(y_val_int, final_val_proba, multi_class='ovr', average='macro')\n",
    "    weighted_roc_auc_val = roc_auc_score(y_val_int, final_val_proba, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    print(f\"\\n宏平均 ROC AUC: {macro_roc_auc_val:.4f}\")\n",
    "    print(f\"加權平均 ROC AUC: {weighted_roc_auc_val:.4f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 測試集完整評估\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Test Metrics for Hierarchical Classification (SVM)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_balanced_acc = balanced_accuracy_score(y_test_int, final_test_pred.astype(int))\n",
    "    print(f\"\\nBalanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\n混淆矩陣:\")\n",
    "    print(confusion_matrix(y_test_int, final_test_pred.astype(int)))\n",
    "    \n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_test_int, final_test_pred.astype(int),\n",
    "                                target_names=list(le.classes_)))\n",
    "    \n",
    "    # 計算測試集概率\n",
    "    final_test_proba = np.zeros((len(y_test_int), 3))\n",
    "    final_test_proba[:, 1] = binary_test_proba[:, 1]  # 健康類別\n",
    "    disease_prob_test = binary_test_proba[:, 0]\n",
    "    final_test_proba[disease_test_indices, 0] = disease_prob_test[disease_test_indices] * disease_test_proba[:, 0]\n",
    "    final_test_proba[disease_test_indices, 2] = disease_prob_test[disease_test_indices] * disease_test_proba[:, 1]\n",
    "    final_test_proba = final_test_proba / (final_test_proba.sum(axis=1, keepdims=True) + 1e-10)\n",
    "    \n",
    "    # ROC AUC\n",
    "    test_binarized = label_binarize(y_test_int, classes=[0, 1, 2])\n",
    "    print(\"\\n每個類別的 ROC AUC:\")\n",
    "    for i, class_name in enumerate(le.classes_):\n",
    "        fpr, tpr, _ = roc_curve(test_binarized[:, i], final_test_proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(f\"  {class_name} (Class {i}): {roc_auc:.4f}\")\n",
    "    \n",
    "    macro_roc_auc_test = roc_auc_score(y_test_int, final_test_proba, multi_class='ovr', average='macro')\n",
    "    weighted_roc_auc_test = roc_auc_score(y_test_int, final_test_proba, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    print(f\"\\n宏平均 ROC AUC: {macro_roc_auc_test:.4f}\")\n",
    "    print(f\"加權平均 ROC AUC: {weighted_roc_auc_test:.4f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 過擬合分析\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"過擬合分析\")\n",
    "    print(\"=\"*60)\n",
    "    overfitting_gap = val_balanced_acc - test_balanced_acc\n",
    "    print(f\"驗證集 Balanced Accuracy: {val_balanced_acc:.4f}\")\n",
    "    print(f\"測試集 Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "    print(f\"過擬合差距: {overfitting_gap:.4f}\")\n",
    "    \n",
    "    if overfitting_gap > 0.15:\n",
    "        print(\"⚠️ 警告：存在明顯過擬合（差距 > 0.15）\")\n",
    "    elif overfitting_gap > 0.10:\n",
    "        print(\"⚠️ 注意：存在一定過擬合（差距 > 0.10）\")\n",
    "    else:\n",
    "        print(\"✓ 過擬合程度在可接受範圍內\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ============================================\n",
    "    # 類別預測分布分析\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"類別預測分布分析\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n驗證集預測分布:\")\n",
    "    val_pred_counts = {le.classes_[i]: np.sum(final_val_pred.astype(int) == i) for i in range(len(le.classes_))}\n",
    "    val_true_counts = {le.classes_[i]: np.sum(y_val_int == i) for i in range(len(le.classes_))}\n",
    "    print(f\"真實分布: {val_true_counts}\")\n",
    "    print(f\"預測分布: {val_pred_counts}\")\n",
    "    \n",
    "    print(\"\\n測試集預測分布:\")\n",
    "    test_pred_counts = {le.classes_[i]: np.sum(final_test_pred.astype(int) == i) for i in range(len(le.classes_))}\n",
    "    test_true_counts = {le.classes_[i]: np.sum(y_test_int == i) for i in range(len(le.classes_))}\n",
    "    print(f\"真實分布: {test_true_counts}\")\n",
    "    print(f\"預測分布: {test_pred_counts}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ 警告：疾病樣本數量不足，無法進行第二步分類\")\n",
    "    print(\"只進行健康 vs 疾病的分類\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 保存結果和繪製 Confusion Matrix\n",
    "# ============================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# 創建結果目錄\n",
    "results_dir = './two_stage_results/SVM'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 保存預測結果到 CSV\n",
    "if disease_mask_train.sum() > 5 and disease_mask_test.sum() > 3:\n",
    "    # 驗證集結果\n",
    "    val_results_df = pd.DataFrame({\n",
    "        'true_label': [le.classes_[i] for i in y_val_int],\n",
    "        'predicted_label': [le.classes_[int(i)] for i in final_val_pred],\n",
    "        'true_label_int': y_val_int,\n",
    "        'predicted_label_int': final_val_pred.astype(int),\n",
    "        'prob_A': final_val_proba[:, 0],\n",
    "        'prob_C': final_val_proba[:, 1],\n",
    "        'prob_F': final_val_proba[:, 2]\n",
    "    })\n",
    "    val_results_df.to_csv(os.path.join(results_dir, 'validation_predictions.csv'), index=False)\n",
    "    print(f\"\\n✓ 驗證集預測結果已保存到: {os.path.join(results_dir, 'validation_predictions.csv')}\")\n",
    "    \n",
    "    # 測試集結果\n",
    "    test_results_df = pd.DataFrame({\n",
    "        'true_label': [le.classes_[i] for i in y_test_int],\n",
    "        'predicted_label': [le.classes_[int(i)] for i in final_test_pred],\n",
    "        'true_label_int': y_test_int,\n",
    "        'predicted_label_int': final_test_pred.astype(int),\n",
    "        'prob_A': final_test_proba[:, 0],\n",
    "        'prob_C': final_test_proba[:, 1],\n",
    "        'prob_F': final_test_proba[:, 2]\n",
    "    })\n",
    "    test_results_df.to_csv(os.path.join(results_dir, 'test_predictions.csv'), index=False)\n",
    "    print(f\"✓ 測試集預測結果已保存到: {os.path.join(results_dir, 'test_predictions.csv')}\")\n",
    "    \n",
    "    # 保存評估指標到文本文件\n",
    "    with open(os.path.join(results_dir, 'evaluation_metrics.txt'), 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"階層式分類評估結果\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(f\"生成時間: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"驗證集結果:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {val_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"宏平均 ROC AUC: {macro_roc_auc_val:.4f}\\n\")\n",
    "        f.write(f\"加權平均 ROC AUC: {weighted_roc_auc_val:.4f}\\n\\n\")\n",
    "        f.write(\"混淆矩陣:\\n\")\n",
    "        f.write(str(confusion_matrix(y_val_int, final_val_pred.astype(int))) + \"\\n\\n\")\n",
    "        f.write(\"分類報告:\\n\")\n",
    "        f.write(classification_report(y_val_int, final_val_pred.astype(int), \n",
    "                                     target_names=list(le.classes_)) + \"\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"測試集結果:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {test_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"宏平均 ROC AUC: {macro_roc_auc_test:.4f}\\n\")\n",
    "        f.write(f\"加權平均 ROC AUC: {weighted_roc_auc_test:.4f}\\n\\n\")\n",
    "        f.write(\"混淆矩陣:\\n\")\n",
    "        f.write(str(confusion_matrix(y_test_int, final_test_pred.astype(int))) + \"\\n\\n\")\n",
    "        f.write(\"分類報告:\\n\")\n",
    "        f.write(classification_report(y_test_int, final_test_pred.astype(int),\n",
    "                                     target_names=list(le.classes_)) + \"\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"過擬合分析:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"驗證集 Balanced Accuracy: {val_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"測試集 Balanced Accuracy: {test_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"過擬合差距: {overfitting_gap:.4f}\\n\")\n",
    "    \n",
    "    print(f\"✓ 評估指標已保存到: {os.path.join(results_dir, 'evaluation_metrics.txt')}\")\n",
    "    \n",
    "    # 繪製 Confusion Matrix\n",
    "    class_names = list(le.classes_)\n",
    "    \n",
    "    # 驗證集 Confusion Matrix\n",
    "    cm_val = confusion_matrix(y_val_int, final_val_pred.astype(int))\n",
    "    cm_val_normalized = cm_val.astype('float') / (cm_val.sum(axis=1)[:, np.newaxis] + 1e-10)\n",
    "    cm_val_normalized = np.nan_to_num(cm_val_normalized)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 原始混淆矩陣\n",
    "    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "    axes[0].set_title('Validation Set Confusion Matrix (Count)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[0].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    \n",
    "    # 歸一化混淆矩陣\n",
    "    sns.heatmap(cm_val_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[1], cbar_kws={'label': 'Percentage'})\n",
    "    axes[1].set_title('Validation Set Confusion Matrix (Percentage)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[1].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    val_cm_path = os.path.join(results_dir, 'confusion_matrix_validation.png')\n",
    "    plt.savefig(val_cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ 驗證集混淆矩陣已保存到: {val_cm_path}\")\n",
    "    \n",
    "    # 測試集 Confusion Matrix\n",
    "    cm_test = confusion_matrix(y_test_int, final_test_pred.astype(int))\n",
    "    cm_test_normalized = cm_test.astype('float') / (cm_test.sum(axis=1)[:, np.newaxis] + 1e-10)\n",
    "    cm_test_normalized = np.nan_to_num(cm_test_normalized)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 原始混淆矩陣\n",
    "    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "    axes[0].set_title('Test Set Confusion Matrix (Count)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[0].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    # 歸一化混淆矩陣\n",
    "    sns.heatmap(cm_test_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[1], cbar_kws={'label': 'Percentage'})\n",
    "    axes[1].set_title('Test Set Confusion Matrix (Percentage)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[1].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    test_cm_path = os.path.join(results_dir, 'confusion_matrix_test.png')\n",
    "    plt.savefig(test_cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ 測試集混淆矩陣已保存到: {test_cm_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"所有結果已保存完成！\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"結果目錄: {results_dir}\")\n",
    "    print(\"保存的文件:\")\n",
    "    print(\"  - validation_predictions.csv (驗證集預測結果)\")\n",
    "    print(\"  - test_predictions.csv (測試集預測結果)\")\n",
    "    print(\"  - evaluation_metrics.txt (評估指標)\")\n",
    "    print(\"  - confusion_matrix_validation.png (驗證集混淆矩陣)\")\n",
    "    print(\"  - confusion_matrix_test.png (測試集混淆矩陣)\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0695db0",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a5b6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "數據分割信息\n",
      "============================================================\n",
      "總樣本數: 88\n",
      "訓練集樣本數: 30 (34.1%)\n",
      "驗證集樣本數: 31 (35.2%)\n",
      "測試集樣本數: 27 (30.7%)\n",
      "\n",
      "類別編碼: {'A': 0, 'C': 1, 'F': 2}\n",
      "訓練集類別分布: {'A': np.int64(12), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "驗證集類別分布: {'A': np.int64(13), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "測試集類別分布: {'A': np.int64(11), 'C': np.int64(9), 'F': np.int64(7)}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "階層式分類：步驟 1 - 健康 vs 疾病（二分類）- 使用 Random Forest\n",
      "============================================================\n",
      "\n",
      "驗證集結果:\n",
      "Balanced Accuracy: 0.5571\n",
      "混淆矩陣:\n",
      "[[15  6]\n",
      " [ 6  4]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    疾病 (A+F)       0.71      0.71      0.71        21\n",
      "      健康 (C)       0.40      0.40      0.40        10\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.56      0.56      0.56        31\n",
      "weighted avg       0.61      0.61      0.61        31\n",
      "\n",
      "ROC AUC: 0.5286\n",
      "\n",
      "測試集結果:\n",
      "Balanced Accuracy: 0.3611\n",
      "混淆矩陣:\n",
      "[[11  7]\n",
      " [ 8  1]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    疾病 (A+F)       0.58      0.61      0.59        18\n",
      "      健康 (C)       0.12      0.11      0.12         9\n",
      "\n",
      "    accuracy                           0.44        27\n",
      "   macro avg       0.35      0.36      0.36        27\n",
      "weighted avg       0.43      0.44      0.44        27\n",
      "\n",
      "ROC AUC: 0.3210\n",
      "\n",
      "============================================================\n",
      "階層式分類：步驟 2 - AD vs FTD（二分類）- 使用 Random Forest\n",
      "============================================================\n",
      "訓練集疾病樣本數: 20\n",
      "驗證集疾病樣本數: 21\n",
      "測試集疾病樣本數: 18\n",
      "\n",
      "疾病樣本分布:\n",
      "訓練集 - A: 12, F: 8\n",
      "驗證集 - A: 13, F: 8\n",
      "測試集 - A: 11, F: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "驗證集結果:\n",
      "Balanced Accuracy: 0.5962\n",
      "混淆矩陣:\n",
      "[[9 4]\n",
      " [4 4]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AD (A)       0.69      0.69      0.69        13\n",
      "     FTD (F)       0.50      0.50      0.50         8\n",
      "\n",
      "    accuracy                           0.62        21\n",
      "   macro avg       0.60      0.60      0.60        21\n",
      "weighted avg       0.62      0.62      0.62        21\n",
      "\n",
      "ROC AUC: 0.6106\n",
      "\n",
      "測試集結果:\n",
      "Balanced Accuracy: 0.4416\n",
      "混淆矩陣:\n",
      "[[5 6]\n",
      " [4 3]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AD (A)       0.56      0.45      0.50        11\n",
      "     FTD (F)       0.33      0.43      0.38         7\n",
      "\n",
      "    accuracy                           0.44        18\n",
      "   macro avg       0.44      0.44      0.44        18\n",
      "weighted avg       0.47      0.44      0.45        18\n",
      "\n",
      "ROC AUC: 0.5455\n",
      "\n",
      "============================================================\n",
      "階層式分類：最終三分類結果（使用 Random Forest）\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Validation Metrics for Hierarchical Classification (Random Forest)\n",
      "============================================================\n",
      "\n",
      "Balanced Accuracy: 0.7308\n",
      "\n",
      "混淆矩陣:\n",
      "[[ 9  0  4]\n",
      " [ 0 10  0]\n",
      " [ 4  0  4]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.69      0.69      0.69        13\n",
      "           C       1.00      1.00      1.00        10\n",
      "           F       0.50      0.50      0.50         8\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.73      0.73      0.73        31\n",
      "weighted avg       0.74      0.74      0.74        31\n",
      "\n",
      "\n",
      "每個類別的 ROC AUC:\n",
      "  A (Class 0): 0.8162\n",
      "  C (Class 1): 1.0000\n",
      "  F (Class 2): 0.6522\n",
      "\n",
      "宏平均 ROC AUC: 0.8228\n",
      "加權平均 ROC AUC: 0.8332\n",
      "\n",
      "============================================================\n",
      "Test Metrics for Hierarchical Classification (Random Forest)\n",
      "============================================================\n",
      "\n",
      "Balanced Accuracy: 0.6277\n",
      "\n",
      "混淆矩陣:\n",
      "[[5 0 6]\n",
      " [0 9 0]\n",
      " [4 0 3]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.56      0.45      0.50        11\n",
      "           C       1.00      1.00      1.00         9\n",
      "           F       0.33      0.43      0.38         7\n",
      "\n",
      "    accuracy                           0.63        27\n",
      "   macro avg       0.63      0.63      0.62        27\n",
      "weighted avg       0.65      0.63      0.63        27\n",
      "\n",
      "\n",
      "每個類別的 ROC AUC:\n",
      "  A (Class 0): 0.7557\n",
      "  C (Class 1): 1.0000\n",
      "  F (Class 2): 0.8500\n",
      "\n",
      "宏平均 ROC AUC: 0.8686\n",
      "加權平均 ROC AUC: 0.8616\n",
      "\n",
      "============================================================\n",
      "特徵重要性分析\n",
      "============================================================\n",
      "\n",
      "步驟 1（健康 vs 疾病）特徵重要性:\n",
      "              feature  importance\n",
      "0    stationary_ratio    0.163293\n",
      "7          avg_degree    0.127592\n",
      "4    spectral_entropy    0.125070\n",
      "3        graph_energy    0.109591\n",
      "5       signal_energy    0.107090\n",
      "1            Tik-norm    0.100967\n",
      "2     Total_Variation    0.100061\n",
      "8  diffusion_distance    0.098541\n",
      "6        signal_power    0.067794\n",
      "\n",
      "步驟 2（AD vs FTD）特徵重要性:\n",
      "              feature  importance\n",
      "0    stationary_ratio    0.200446\n",
      "6        signal_power    0.177960\n",
      "5       signal_energy    0.154060\n",
      "2     Total_Variation    0.146150\n",
      "7          avg_degree    0.102817\n",
      "1            Tik-norm    0.079369\n",
      "4    spectral_entropy    0.063073\n",
      "3        graph_energy    0.048983\n",
      "8  diffusion_distance    0.027142\n",
      "\n",
      "============================================================\n",
      "過擬合分析\n",
      "============================================================\n",
      "驗證集 Balanced Accuracy: 0.7308\n",
      "測試集 Balanced Accuracy: 0.6277\n",
      "過擬合差距: 0.1031\n",
      "⚠️ 注意：存在一定過擬合（差距 > 0.10）\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "類別預測分布分析\n",
      "============================================================\n",
      "\n",
      "驗證集預測分布:\n",
      "真實分布: {'A': np.int64(13), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "預測分布: {'A': np.int64(13), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "\n",
      "測試集預測分布:\n",
      "真實分布: {'A': np.int64(11), 'C': np.int64(9), 'F': np.int64(7)}\n",
      "預測分布: {'A': np.int64(9), 'C': np.int64(9), 'F': np.int64(9)}\n",
      "============================================================\n",
      "\n",
      "✓ 驗證集預測結果已保存到: ./two_stage_results/random_forest/validation_predictions.csv\n",
      "✓ 測試集預測結果已保存到: ./two_stage_results/random_forest/test_predictions.csv\n",
      "✓ 評估指標已保存到: ./two_stage_results/random_forest/evaluation_metrics.txt\n",
      "✓ 驗證集混淆矩陣已保存到: ./two_stage_results/random_forest/confusion_matrix_validation.png\n",
      "✓ 測試集混淆矩陣已保存到: ./two_stage_results/random_forest/confusion_matrix_test.png\n",
      "\n",
      "============================================================\n",
      "所有結果已保存完成！\n",
      "============================================================\n",
      "結果目錄: ./two_stage_results/random_forest\n",
      "保存的文件:\n",
      "  - validation_predictions.csv (驗證集預測結果)\n",
      "  - test_predictions.csv (測試集預測結果)\n",
      "  - evaluation_metrics.txt (評估指標)\n",
      "  - confusion_matrix_validation.png (驗證集混淆矩陣)\n",
      "  - confusion_matrix_test.png (測試集混淆矩陣)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 完整階層式分類程式（使用 Random Forest）\n",
    "# ============================================\n",
    "\n",
    "# ============================================\n",
    "# 步驟 0: 資料載入和預處理\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                            balanced_accuracy_score, roc_auc_score,\n",
    "                            roc_curve, auc)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 設置數據路徑\n",
    "base_dir = r'./'\n",
    "dataset_dir = os.path.join(base_dir, 'ds004504')\n",
    "\n",
    "# 讀取特徵數據\n",
    "features_df = pd.read_csv(os.path.join(base_dir, \"features_tv.csv\"))\n",
    "# 讀取參與者信息\n",
    "participants = pd.read_csv(os.path.join(dataset_dir, \"participants.tsv\"), delimiter='\\t')\n",
    "\n",
    "# 合併數據\n",
    "data = features_df.merge(participants, left_index=True, right_index=True)\n",
    "\n",
    "# 定義特徵字典\n",
    "features = {\n",
    "    'stationary_ratio': 'Stationary Ratio',\n",
    "    'Tik-norm': 'Tik-norm',\n",
    "    'Total_Variation': 'Total Variation',\n",
    "    'graph_energy': 'Graph Energy',\n",
    "    'spectral_entropy': 'Spectral Entropy',\n",
    "    'signal_energy': 'Signal Energy',\n",
    "    'signal_power': 'Signal Power',\n",
    "    'avg_degree': 'Average Degree',\n",
    "    'diffusion_distance': 'Diffusion Distance',\n",
    "}\n",
    "\n",
    "# 準備特徵和標籤\n",
    "X = data[list(features.keys())].copy()\n",
    "y = data['Group'].copy()\n",
    "\n",
    "# 數據清理\n",
    "for col in X.columns:\n",
    "    first_val = X[col].iloc[0] if len(X) > 0 else None\n",
    "    if isinstance(first_val, str):\n",
    "        def safe_convert(x):\n",
    "            if pd.isna(x):\n",
    "                return np.nan\n",
    "            if isinstance(x, str):\n",
    "                try:\n",
    "                    parsed = ast.literal_eval(x)\n",
    "                    if isinstance(parsed, (list, tuple, np.ndarray)):\n",
    "                        return float(parsed[0]) if len(parsed) > 0 else np.nan\n",
    "                    return float(parsed)\n",
    "                except:\n",
    "                    try:\n",
    "                        return float(x)\n",
    "                    except:\n",
    "                        try:\n",
    "                            parsed = eval('[' + ','.join(x.strip('[]').split()) + ']')\n",
    "                            return float(parsed[0]) if len(parsed) > 0 else np.nan\n",
    "                        except:\n",
    "                            return np.nan\n",
    "            try:\n",
    "                return float(x) if pd.notna(x) else np.nan\n",
    "            except:\n",
    "                return np.nan\n",
    "        X[col] = X[col].apply(safe_convert)\n",
    "    else:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "rows_with_all_nan = X.isna().all(axis=1)\n",
    "valid_mask = ~(rows_with_all_nan | y.isna())\n",
    "X = X[valid_mask].copy()\n",
    "y = y[valid_mask].copy()\n",
    "\n",
    "if X.isna().sum().sum() > 0:\n",
    "    for col in X.columns:\n",
    "        if X[col].isna().sum() > 0:\n",
    "            median_val = X[col].median()\n",
    "            X[col] = X[col].fillna(median_val)\n",
    "\n",
    "X = X.astype(float)\n",
    "\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"錯誤：清理後數據為空！請檢查原始數據。\")\n",
    "\n",
    "# 數據分割（目標比例：訓練集 30, 驗證集 31, 測試集 27）\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=27/88, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=31/61, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_val = X_val.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# 標準化\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 編碼標籤\n",
    "le = LabelEncoder()\n",
    "y_train_int = le.fit_transform(y_train)\n",
    "y_val_int = le.transform(y_val)\n",
    "y_test_int = le.transform(y_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"數據分割信息\")\n",
    "print(\"=\"*60)\n",
    "print(f\"總樣本數: {len(X)}\")\n",
    "print(f\"訓練集樣本數: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"驗證集樣本數: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"測試集樣本數: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\n類別編碼: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
    "print(f\"訓練集類別分布: {dict(zip(le.classes_, np.bincount(y_train_int)))}\")\n",
    "print(f\"驗證集類別分布: {dict(zip(le.classes_, np.bincount(y_val_int)))}\")\n",
    "print(f\"測試集類別分布: {dict(zip(le.classes_, np.bincount(y_test_int)))}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# 步驟 1：健康 vs 疾病（二分類）- 使用 Random Forest\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"階層式分類：步驟 1 - 健康 vs 疾病（二分類）- 使用 Random Forest\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_binary_train = (y_train_int == 1).astype(int)  # C=1 是健康，A 和 F 是疾病\n",
    "y_binary_val = (y_val_int == 1).astype(int)\n",
    "y_binary_test = (y_test_int == 1).astype(int)\n",
    "\n",
    "# 訓練 Random Forest 二分類模型\n",
    "binary_model = RandomForestClassifier(\n",
    "    n_estimators=50,  # 樹的數量\n",
    "    max_depth=3,  # 限制深度防止過擬合\n",
    "    min_samples_split=5,  # 內部節點最小樣本數\n",
    "    min_samples_leaf=3,  # 葉節點最小樣本數\n",
    "    max_features='sqrt',  # 每次分割考慮的特徵數\n",
    "    class_weight='balanced',  # 處理類別不平衡\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # 使用所有 CPU 核心\n",
    ")\n",
    "\n",
    "binary_model.fit(X_train_scaled, y_binary_train)\n",
    "\n",
    "# 驗證集預測\n",
    "binary_val_pred = binary_model.predict(X_val_scaled)\n",
    "binary_val_proba = binary_model.predict_proba(X_val_scaled)\n",
    "\n",
    "# 測試集預測\n",
    "binary_test_pred = binary_model.predict(X_test_scaled)\n",
    "binary_test_proba = binary_model.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"\\n驗證集結果:\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_binary_val, binary_val_pred):.4f}\")\n",
    "print(f\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_binary_val, binary_val_pred))\n",
    "print(f\"\\n分類報告:\")\n",
    "print(classification_report(y_binary_val, binary_val_pred, \n",
    "                            target_names=['疾病 (A+F)', '健康 (C)']))\n",
    "\n",
    "# ROC AUC\n",
    "binary_val_roc = roc_auc_score(y_binary_val, binary_val_proba[:, 1])\n",
    "print(f\"ROC AUC: {binary_val_roc:.4f}\")\n",
    "\n",
    "print(\"\\n測試集結果:\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_binary_test, binary_test_pred):.4f}\")\n",
    "print(f\"混淆矩陣:\")\n",
    "print(confusion_matrix(y_binary_test, binary_test_pred))\n",
    "print(f\"\\n分類報告:\")\n",
    "print(classification_report(y_binary_test, binary_test_pred,\n",
    "                            target_names=['疾病 (A+F)', '健康 (C)']))\n",
    "\n",
    "# ROC AUC\n",
    "binary_test_roc = roc_auc_score(y_binary_test, binary_test_proba[:, 1])\n",
    "print(f\"ROC AUC: {binary_test_roc:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 步驟 2：在疾病樣本中區分 A 和 F - 使用 Random Forest\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"階層式分類：步驟 2 - AD vs FTD（二分類）- 使用 Random Forest\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "disease_mask_train = y_train_int != 1\n",
    "disease_mask_val = y_val_int != 1\n",
    "disease_mask_test = y_test_int != 1\n",
    "\n",
    "print(f\"訓練集疾病樣本數: {disease_mask_train.sum()}\")\n",
    "print(f\"驗證集疾病樣本數: {disease_mask_val.sum()}\")\n",
    "print(f\"測試集疾病樣本數: {disease_mask_test.sum()}\")\n",
    "\n",
    "if disease_mask_train.sum() > 5 and disease_mask_test.sum() > 3:\n",
    "    # 準備疾病樣本資料\n",
    "    X_disease_train = X_train_scaled[disease_mask_train]\n",
    "    y_disease_train = y_train_int[disease_mask_train]\n",
    "    y_disease_train_binary = (y_disease_train == 2).astype(int)  # A=0, F=1\n",
    "    \n",
    "    X_disease_val = X_val_scaled[disease_mask_val]\n",
    "    y_disease_val = y_val_int[disease_mask_val]\n",
    "    y_disease_val_binary = (y_disease_val == 2).astype(int)\n",
    "    \n",
    "    X_disease_test = X_test_scaled[disease_mask_test]\n",
    "    y_disease_test = y_test_int[disease_mask_test]\n",
    "    y_disease_test_binary = (y_disease_test == 2).astype(int)\n",
    "    \n",
    "    print(f\"\\n疾病樣本分布:\")\n",
    "    print(f\"訓練集 - A: {np.sum(y_disease_train_binary == 0)}, F: {np.sum(y_disease_train_binary == 1)}\")\n",
    "    print(f\"驗證集 - A: {np.sum(y_disease_val_binary == 0)}, F: {np.sum(y_disease_val_binary == 1)}\")\n",
    "    print(f\"測試集 - A: {np.sum(y_disease_test_binary == 0)}, F: {np.sum(y_disease_test_binary == 1)}\")\n",
    "    \n",
    "    # 訓練 Random Forest 疾病分類模型\n",
    "    disease_model = RandomForestClassifier(\n",
    "        n_estimators=30,  # 較少的樹（因為樣本更少）\n",
    "        max_depth=2,  # 更淺的樹\n",
    "        min_samples_split=3,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    disease_model.fit(X_disease_train, y_disease_train_binary)\n",
    "    \n",
    "    # 驗證集預測\n",
    "    disease_val_pred = disease_model.predict(X_disease_val)\n",
    "    disease_val_proba = disease_model.predict_proba(X_disease_val)\n",
    "    \n",
    "    # 測試集預測\n",
    "    disease_test_pred = disease_model.predict(X_disease_test)\n",
    "    disease_test_proba = disease_model.predict_proba(X_disease_test)\n",
    "    \n",
    "    print(\"\\n驗證集結果:\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_disease_val_binary, disease_val_pred):.4f}\")\n",
    "    print(f\"混淆矩陣:\")\n",
    "    print(confusion_matrix(y_disease_val_binary, disease_val_pred))\n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_disease_val_binary, disease_val_pred,\n",
    "                                target_names=['AD (A)', 'FTD (F)']))\n",
    "    \n",
    "    # ROC AUC\n",
    "    if len(np.unique(y_disease_val_binary)) > 1:\n",
    "        disease_val_roc = roc_auc_score(y_disease_val_binary, disease_val_proba[:, 1])\n",
    "        print(f\"ROC AUC: {disease_val_roc:.4f}\")\n",
    "    \n",
    "    print(\"\\n測試集結果:\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_disease_test_binary, disease_test_pred):.4f}\")\n",
    "    print(f\"混淆矩陣:\")\n",
    "    print(confusion_matrix(y_disease_test_binary, disease_test_pred))\n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_disease_test_binary, disease_test_pred,\n",
    "                                target_names=['AD (A)', 'FTD (F)']))\n",
    "    \n",
    "    # ROC AUC\n",
    "    if len(np.unique(y_disease_test_binary)) > 1:\n",
    "        disease_test_roc = roc_auc_score(y_disease_test_binary, disease_test_proba[:, 1])\n",
    "        print(f\"ROC AUC: {disease_test_roc:.4f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 步驟 3：組合預測（三分類最終結果）\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"階層式分類：最終三分類結果（使用 Random Forest）\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 驗證集組合預測\n",
    "    final_val_pred = np.zeros(len(y_val_int))\n",
    "    final_val_pred[y_binary_val == 1] = 1  # 健康 = C (1)\n",
    "    disease_val_indices = np.where(y_binary_val == 0)[0]\n",
    "    # 如果預測為疾病，則使用疾病分類器的預測：A=0, F=2\n",
    "    final_val_pred[disease_val_indices] = disease_val_pred * 2\n",
    "    \n",
    "    # 測試集組合預測\n",
    "    final_test_pred = np.zeros(len(y_test_int))\n",
    "    final_test_pred[y_binary_test == 1] = 1  # 健康 = C (1)\n",
    "    disease_test_indices = np.where(y_binary_test == 0)[0]\n",
    "    # 如果預測為疾病，則使用疾病分類器的預測：A=0, F=2\n",
    "    final_test_pred[disease_test_indices] = disease_test_pred * 2\n",
    "    \n",
    "    # ============================================\n",
    "    # 驗證集完整評估\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Validation Metrics for Hierarchical Classification (Random Forest)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    val_balanced_acc = balanced_accuracy_score(y_val_int, final_val_pred.astype(int))\n",
    "    print(f\"\\nBalanced Accuracy: {val_balanced_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\n混淆矩陣:\")\n",
    "    print(confusion_matrix(y_val_int, final_val_pred.astype(int)))\n",
    "    \n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_val_int, final_val_pred.astype(int), \n",
    "                                target_names=list(le.classes_)))\n",
    "    \n",
    "    # 計算每個類別的預測概率（用於 ROC AUC）\n",
    "    final_val_proba = np.zeros((len(y_val_int), 3))\n",
    "    \n",
    "    # 健康類別（C）的概率\n",
    "    final_val_proba[:, 1] = binary_val_proba[:, 1]\n",
    "    \n",
    "    # 疾病類別的概率 = P(疾病) * P(具體疾病類型|疾病)\n",
    "    disease_prob = binary_val_proba[:, 0]  # P(疾病)\n",
    "    final_val_proba[disease_val_indices, 0] = disease_prob[disease_val_indices] * disease_val_proba[:, 0]  # A\n",
    "    final_val_proba[disease_val_indices, 2] = disease_prob[disease_val_indices] * disease_val_proba[:, 1]  # F\n",
    "    \n",
    "    # 歸一化概率\n",
    "    final_val_proba = final_val_proba / (final_val_proba.sum(axis=1, keepdims=True) + 1e-10)\n",
    "    \n",
    "    # ROC AUC\n",
    "    val_binarized = label_binarize(y_val_int, classes=[0, 1, 2])\n",
    "    print(\"\\n每個類別的 ROC AUC:\")\n",
    "    for i, class_name in enumerate(le.classes_):\n",
    "        fpr, tpr, _ = roc_curve(val_binarized[:, i], final_val_proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(f\"  {class_name} (Class {i}): {roc_auc:.4f}\")\n",
    "    \n",
    "    macro_roc_auc_val = roc_auc_score(y_val_int, final_val_proba, multi_class='ovr', average='macro')\n",
    "    weighted_roc_auc_val = roc_auc_score(y_val_int, final_val_proba, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    print(f\"\\n宏平均 ROC AUC: {macro_roc_auc_val:.4f}\")\n",
    "    print(f\"加權平均 ROC AUC: {weighted_roc_auc_val:.4f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 測試集完整評估\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Test Metrics for Hierarchical Classification (Random Forest)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_balanced_acc = balanced_accuracy_score(y_test_int, final_test_pred.astype(int))\n",
    "    print(f\"\\nBalanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\n混淆矩陣:\")\n",
    "    print(confusion_matrix(y_test_int, final_test_pred.astype(int)))\n",
    "    \n",
    "    print(f\"\\n分類報告:\")\n",
    "    print(classification_report(y_test_int, final_test_pred.astype(int),\n",
    "                                target_names=list(le.classes_)))\n",
    "    \n",
    "    # 計算測試集概率\n",
    "    final_test_proba = np.zeros((len(y_test_int), 3))\n",
    "    final_test_proba[:, 1] = binary_test_proba[:, 1]  # 健康類別\n",
    "    disease_prob_test = binary_test_proba[:, 0]\n",
    "    final_test_proba[disease_test_indices, 0] = disease_prob_test[disease_test_indices] * disease_test_proba[:, 0]\n",
    "    final_test_proba[disease_test_indices, 2] = disease_prob_test[disease_test_indices] * disease_test_proba[:, 1]\n",
    "    final_test_proba = final_test_proba / (final_test_proba.sum(axis=1, keepdims=True) + 1e-10)\n",
    "    \n",
    "    # ROC AUC\n",
    "    test_binarized = label_binarize(y_test_int, classes=[0, 1, 2])\n",
    "    print(\"\\n每個類別的 ROC AUC:\")\n",
    "    for i, class_name in enumerate(le.classes_):\n",
    "        fpr, tpr, _ = roc_curve(test_binarized[:, i], final_test_proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(f\"  {class_name} (Class {i}): {roc_auc:.4f}\")\n",
    "    \n",
    "    macro_roc_auc_test = roc_auc_score(y_test_int, final_test_proba, multi_class='ovr', average='macro')\n",
    "    weighted_roc_auc_test = roc_auc_score(y_test_int, final_test_proba, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    print(f\"\\n宏平均 ROC AUC: {macro_roc_auc_test:.4f}\")\n",
    "    print(f\"加權平均 ROC AUC: {weighted_roc_auc_test:.4f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # 特徵重要性分析（Random Forest 特有）\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"特徵重要性分析\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n步驟 1（健康 vs 疾病）特徵重要性:\")\n",
    "    feature_importance_binary = pd.DataFrame({\n",
    "        'feature': list(features.keys()),\n",
    "        'importance': binary_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    print(feature_importance_binary)\n",
    "    \n",
    "    print(\"\\n步驟 2（AD vs FTD）特徵重要性:\")\n",
    "    feature_importance_disease = pd.DataFrame({\n",
    "        'feature': list(features.keys()),\n",
    "        'importance': disease_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    print(feature_importance_disease)\n",
    "    \n",
    "    # ============================================\n",
    "    # 過擬合分析\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"過擬合分析\")\n",
    "    print(\"=\"*60)\n",
    "    overfitting_gap = val_balanced_acc - test_balanced_acc\n",
    "    print(f\"驗證集 Balanced Accuracy: {val_balanced_acc:.4f}\")\n",
    "    print(f\"測試集 Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "    print(f\"過擬合差距: {overfitting_gap:.4f}\")\n",
    "    \n",
    "    if overfitting_gap > 0.15:\n",
    "        print(\"⚠️ 警告：存在明顯過擬合（差距 > 0.15）\")\n",
    "        print(\"   建議：增加 max_depth 限制或增加 min_samples_split/min_samples_leaf\")\n",
    "    elif overfitting_gap > 0.10:\n",
    "        print(\"⚠️ 注意：存在一定過擬合（差距 > 0.10）\")\n",
    "    else:\n",
    "        print(\"✓ 過擬合程度在可接受範圍內\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ============================================\n",
    "    # 類別預測分布分析\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"類別預測分布分析\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n驗證集預測分布:\")\n",
    "    val_pred_counts = {le.classes_[i]: np.sum(final_val_pred.astype(int) == i) for i in range(len(le.classes_))}\n",
    "    val_true_counts = {le.classes_[i]: np.sum(y_val_int == i) for i in range(len(le.classes_))}\n",
    "    print(f\"真實分布: {val_true_counts}\")\n",
    "    print(f\"預測分布: {val_pred_counts}\")\n",
    "    \n",
    "    print(\"\\n測試集預測分布:\")\n",
    "    test_pred_counts = {le.classes_[i]: np.sum(final_test_pred.astype(int) == i) for i in range(len(le.classes_))}\n",
    "    test_true_counts = {le.classes_[i]: np.sum(y_test_int == i) for i in range(len(le.classes_))}\n",
    "    print(f\"真實分布: {test_true_counts}\")\n",
    "    print(f\"預測分布: {test_pred_counts}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ 警告：疾病樣本數量不足，無法進行第二步分類\")\n",
    "    print(\"只進行健康 vs 疾病的分類\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 保存結果和繪製 Confusion Matrix\n",
    "# ============================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# 創建結果目錄\n",
    "results_dir = './two_stage_results/random_forest'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 保存預測結果到 CSV\n",
    "if disease_mask_train.sum() > 5 and disease_mask_test.sum() > 3:\n",
    "    # 驗證集結果\n",
    "    val_results_df = pd.DataFrame({\n",
    "        'true_label': [le.classes_[i] for i in y_val_int],\n",
    "        'predicted_label': [le.classes_[int(i)] for i in final_val_pred],\n",
    "        'true_label_int': y_val_int,\n",
    "        'predicted_label_int': final_val_pred.astype(int),\n",
    "        'prob_A': final_val_proba[:, 0],\n",
    "        'prob_C': final_val_proba[:, 1],\n",
    "        'prob_F': final_val_proba[:, 2]\n",
    "    })\n",
    "    val_results_df.to_csv(os.path.join(results_dir, 'validation_predictions.csv'), index=False)\n",
    "    print(f\"\\n✓ 驗證集預測結果已保存到: {os.path.join(results_dir, 'validation_predictions.csv')}\")\n",
    "    \n",
    "    # 測試集結果\n",
    "    test_results_df = pd.DataFrame({\n",
    "        'true_label': [le.classes_[i] for i in y_test_int],\n",
    "        'predicted_label': [le.classes_[int(i)] for i in final_test_pred],\n",
    "        'true_label_int': y_test_int,\n",
    "        'predicted_label_int': final_test_pred.astype(int),\n",
    "        'prob_A': final_test_proba[:, 0],\n",
    "        'prob_C': final_test_proba[:, 1],\n",
    "        'prob_F': final_test_proba[:, 2]\n",
    "    })\n",
    "    test_results_df.to_csv(os.path.join(results_dir, 'test_predictions.csv'), index=False)\n",
    "    print(f\"✓ 測試集預測結果已保存到: {os.path.join(results_dir, 'test_predictions.csv')}\")\n",
    "    \n",
    "    # 保存評估指標到文本文件\n",
    "    with open(os.path.join(results_dir, 'evaluation_metrics.txt'), 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"階層式分類評估結果\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(f\"生成時間: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"驗證集結果:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {val_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"宏平均 ROC AUC: {macro_roc_auc_val:.4f}\\n\")\n",
    "        f.write(f\"加權平均 ROC AUC: {weighted_roc_auc_val:.4f}\\n\\n\")\n",
    "        f.write(\"混淆矩陣:\\n\")\n",
    "        f.write(str(confusion_matrix(y_val_int, final_val_pred.astype(int))) + \"\\n\\n\")\n",
    "        f.write(\"分類報告:\\n\")\n",
    "        f.write(classification_report(y_val_int, final_val_pred.astype(int), \n",
    "                                     target_names=list(le.classes_)) + \"\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"測試集結果:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {test_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"宏平均 ROC AUC: {macro_roc_auc_test:.4f}\\n\")\n",
    "        f.write(f\"加權平均 ROC AUC: {weighted_roc_auc_test:.4f}\\n\\n\")\n",
    "        f.write(\"混淆矩陣:\\n\")\n",
    "        f.write(str(confusion_matrix(y_test_int, final_test_pred.astype(int))) + \"\\n\\n\")\n",
    "        f.write(\"分類報告:\\n\")\n",
    "        f.write(classification_report(y_test_int, final_test_pred.astype(int),\n",
    "                                     target_names=list(le.classes_)) + \"\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"過擬合分析:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"驗證集 Balanced Accuracy: {val_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"測試集 Balanced Accuracy: {test_balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"過擬合差距: {overfitting_gap:.4f}\\n\")\n",
    "    \n",
    "    print(f\"✓ 評估指標已保存到: {os.path.join(results_dir, 'evaluation_metrics.txt')}\")\n",
    "    \n",
    "    # 繪製 Confusion Matrix\n",
    "    class_names = list(le.classes_)\n",
    "    \n",
    "    # 驗證集 Confusion Matrix\n",
    "    cm_val = confusion_matrix(y_val_int, final_val_pred.astype(int))\n",
    "    cm_val_normalized = cm_val.astype('float') / (cm_val.sum(axis=1)[:, np.newaxis] + 1e-10)\n",
    "    cm_val_normalized = np.nan_to_num(cm_val_normalized)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 原始混淆矩陣\n",
    "    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "    axes[0].set_title('Validation Set Confusion Matrix (Count)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[0].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    \n",
    "    # 歸一化混淆矩陣\n",
    "    sns.heatmap(cm_val_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[1], cbar_kws={'label': 'Percentage'})\n",
    "    axes[1].set_title('Validation Set Confusion Matrix (Percentage)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[1].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    val_cm_path = os.path.join(results_dir, 'confusion_matrix_validation.png')\n",
    "    plt.savefig(val_cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ 驗證集混淆矩陣已保存到: {val_cm_path}\")\n",
    "    \n",
    "    # 測試集 Confusion Matrix\n",
    "    cm_test = confusion_matrix(y_test_int, final_test_pred.astype(int))\n",
    "    cm_test_normalized = cm_test.astype('float') / (cm_test.sum(axis=1)[:, np.newaxis] + 1e-10)\n",
    "    cm_test_normalized = np.nan_to_num(cm_test_normalized)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 原始混淆矩陣\n",
    "    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "    axes[0].set_title('Test Set Confusion Matrix (Count)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[0].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    # 歸一化混淆矩陣\n",
    "    sns.heatmap(cm_test_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "               xticklabels=class_names, yticklabels=class_names,\n",
    "               ax=axes[1], cbar_kws={'label': 'Percentage'})\n",
    "    axes[1].set_title('Test Set Confusion Matrix (Percentage)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[1].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    test_cm_path = os.path.join(results_dir, 'confusion_matrix_test.png')\n",
    "    plt.savefig(test_cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ 測試集混淆矩陣已保存到: {test_cm_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"所有結果已保存完成！\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"結果目錄: {results_dir}\")\n",
    "    print(\"保存的文件:\")\n",
    "    print(\"  - validation_predictions.csv (驗證集預測結果)\")\n",
    "    print(\"  - test_predictions.csv (測試集預測結果)\")\n",
    "    print(\"  - evaluation_metrics.txt (評估指標)\")\n",
    "    print(\"  - confusion_matrix_validation.png (驗證集混淆矩陣)\")\n",
    "    print(\"  - confusion_matrix_test.png (測試集混淆矩陣)\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879cc79",
   "metadata": {},
   "source": [
    "### MLP (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465f67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "數據分割信息\n",
      "============================================================\n",
      "總樣本數: 88\n",
      "訓練集樣本數: 30 (34.1%)\n",
      "驗證集樣本數: 31 (35.2%)\n",
      "測試集樣本數: 27 (30.7%)\n",
      "============================================================\n",
      "============================================================\n",
      "數據集信息\n",
      "============================================================\n",
      "訓練集類別分布: {'A': np.int64(12), 'C': np.int64(12), 'F': np.int64(6)}\n",
      "驗證集類別分布: {'A': np.int64(11), 'C': np.int64(13), 'F': np.int64(7)}\n",
      "測試集類別分布: {'A': np.int64(13), 'C': np.int64(4), 'F': np.int64(10)}\n",
      "類別權重: {'A': np.float64(0.8333333333333334), 'C': np.float64(0.8333333333333334), 'F': np.float64(1.6666666666666667)}\n",
      "樣本權重範圍: 0.833 - 1.667\n",
      "\n",
      "============================================================\n",
      "模型複雜度分析\n",
      "============================================================\n",
      "特徵數量: 9\n",
      "類別數量: 3\n",
      "訓練樣本數: 30\n",
      "\n",
      "不同架構的參數數量估算:\n",
      "  (3,): 42 參數, 比例 1.40 ✗\n",
      "  (4,): 55 參數, 比例 1.83 ✗\n",
      "  (5,): 68 參數, 比例 2.27 ✗\n",
      "  (6,): 81 參數, 比例 2.70 ✗\n",
      "  (8,): 107 參數, 比例 3.57 ✗\n",
      "  (10,): 133 參數, 比例 4.43 ✗\n",
      "============================================================\n",
      "============================================================\n",
      "開始 Fine-tune 網格搜索（極簡化單層配置）...\n",
      "============================================================\n",
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "\n",
      "最佳參數: {'activation': 'tanh', 'alpha': 15.0, 'beta_1': 0.9, 'beta_2': 0.999, 'hidden_layer_sizes': (4,), 'learning_rate': 'constant', 'learning_rate_init': 0.01}\n",
      "最佳交叉驗證 Balanced Accuracy: 0.4333\n",
      "\n",
      "估計參數數量: 55\n",
      "訓練樣本數量: 30\n",
      "參數/樣本比例: 1.83 ✗ (仍然太高)\n",
      "\n",
      "============================================================\n",
      "最終使用的網絡架構\n",
      "============================================================\n",
      "hidden_layer_sizes: (4,)\n",
      "架構類型: 單層MLP\n",
      "  隱藏層: 4 個神經元\n",
      "\n",
      "其他重要參數:\n",
      "  激活函數: tanh\n",
      "  正則化參數 (alpha): 15.0\n",
      "  學習率: constant\n",
      "  初始學習率: 0.01\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Validation Metrics for Fine-tuned MLPClassifier Model\n",
      "============================================================\n",
      "\n",
      "混淆矩陣:\n",
      "[[4 7 0]\n",
      " [5 8 0]\n",
      " [3 4 0]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.33      0.36      0.35        11\n",
      "           C       0.42      0.62      0.50        13\n",
      "           F       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.39        31\n",
      "   macro avg       0.25      0.33      0.28        31\n",
      "weighted avg       0.29      0.39      0.33        31\n",
      "\n",
      "\n",
      "每個類別的 ROC AUC:\n",
      "  A (Class 0): 0.5273\n",
      "  C (Class 1): 0.5556\n",
      "  F (Class 2): 0.6429\n",
      "\n",
      "宏平均 ROC AUC: 0.5752\n",
      "加權平均 ROC AUC: 0.5652\n",
      "Balanced Accuracy: 0.3263\n",
      "\n",
      "============================================================\n",
      "Test Metrics for Fine-tuned MLPClassifier Model\n",
      "============================================================\n",
      "\n",
      "混淆矩陣:\n",
      "[[4 9 0]\n",
      " [0 4 0]\n",
      " [9 1 0]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.31      0.31      0.31        13\n",
      "           C       0.29      1.00      0.44         4\n",
      "           F       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.30        27\n",
      "   macro avg       0.20      0.44      0.25        27\n",
      "weighted avg       0.19      0.30      0.21        27\n",
      "\n",
      "\n",
      "每個類別的 ROC AUC:\n",
      "  A (Class 0): 0.2527\n",
      "  C (Class 1): 0.6957\n",
      "  F (Class 2): 0.8353\n",
      "\n",
      "宏平均 ROC AUC: 0.5946\n",
      "加權平均 ROC AUC: 0.5341\n",
      "Balanced Accuracy: 0.4359\n",
      "\n",
      "============================================================\n",
      "過擬合分析\n",
      "============================================================\n",
      "驗證集 Balanced Accuracy: 0.3263\n",
      "測試集 Balanced Accuracy: 0.4359\n",
      "過擬合差距: -0.1096\n",
      "✓ 過擬合程度在可接受範圍內\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 準備特徵和標籤\n",
    "X = data[list(features.keys())].copy()\n",
    "y = data['Group'].copy()\n",
    "\n",
    "# 數據清理（與之前相同）\n",
    "for col in X.columns:\n",
    "    first_val = X[col].iloc[0] if len(X) > 0 else None\n",
    "    if isinstance(first_val, str):\n",
    "        def safe_convert(x):\n",
    "            if pd.isna(x):\n",
    "                return np.nan\n",
    "            if isinstance(x, str):\n",
    "                try:\n",
    "                    parsed = ast.literal_eval(x)\n",
    "                    if isinstance(parsed, (list, tuple, np.ndarray)):\n",
    "                        return float(parsed[0]) if len(parsed) > 0 else np.nan\n",
    "                    return float(parsed)\n",
    "                except:\n",
    "                    try:\n",
    "                        return float(x)\n",
    "                    except:\n",
    "                        try:\n",
    "                            parsed = eval('[' + ','.join(x.strip('[]').split()) + ']')\n",
    "                            return float(parsed[0]) if len(parsed) > 0 else np.nan\n",
    "                        except:\n",
    "                            return np.nan\n",
    "            try:\n",
    "                return float(x) if pd.notna(x) else np.nan\n",
    "            except:\n",
    "                return np.nan\n",
    "        X[col] = X[col].apply(safe_convert)\n",
    "    else:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "rows_with_all_nan = X.isna().all(axis=1)\n",
    "valid_mask = ~(rows_with_all_nan | y.isna())\n",
    "X = X[valid_mask].copy()\n",
    "y = y[valid_mask].copy()\n",
    "\n",
    "if X.isna().sum().sum() > 0:\n",
    "    for col in X.columns:\n",
    "        if X[col].isna().sum() > 0:\n",
    "            median_val = X[col].median()\n",
    "            X[col] = X[col].fillna(median_val)\n",
    "\n",
    "X = X.astype(float)\n",
    "\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"錯誤：清理後數據為空！請檢查原始數據。\")\n",
    "\n",
    "# Split the data into train+validation set and test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Further split the train data into train set and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_val = X_val.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 編碼標籤\n",
    "le = LabelEncoder()\n",
    "y_train_int = le.fit_transform(y_train)\n",
    "y_val_int = le.transform(y_val)\n",
    "y_test_int = le.transform(y_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"數據分割信息\")\n",
    "print(\"=\"*60)\n",
    "print(f\"總樣本數: {len(X)}\")\n",
    "print(f\"訓練集樣本數: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"驗證集樣本數: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"測試集樣本數: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"數據集信息\")\n",
    "print(\"=\"*60)\n",
    "print(f\"訓練集類別分布: {dict(zip(le.classes_, np.bincount(y_train_int)))}\")\n",
    "print(f\"驗證集類別分布: {dict(zip(le.classes_, np.bincount(y_val_int)))}\")\n",
    "print(f\"測試集類別分布: {dict(zip(le.classes_, np.bincount(y_test_int)))}\")\n",
    "\n",
    "# 使用標準的 balanced 權重\n",
    "class_counts = np.bincount(y_train_int)\n",
    "total_samples = len(y_train_int)\n",
    "n_classes = len(class_counts)\n",
    "\n",
    "class_weights = total_samples / (n_classes * class_counts)\n",
    "sample_weights = np.array([class_weights[y] for y in y_train_int])\n",
    "\n",
    "print(f\"類別權重: {dict(zip(le.classes_, class_weights))}\")\n",
    "print(f\"樣本權重範圍: {sample_weights.min():.3f} - {sample_weights.max():.3f}\\n\")\n",
    "\n",
    "# WeightedMLPClassifier 類\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class WeightedMLPClassifier(BaseEstimator, ClassifierMixin):\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.mlp = MLPClassifier(**kwargs)\n",
    "        self.sample_weights = None\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        self.sample_weights = sample_weight\n",
    "        self.mlp.fit(X, y, sample_weight=sample_weight)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.mlp.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.mlp.predict_proba(X)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return self.mlp.get_params(deep=deep)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        self.mlp.set_params(**params)\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.mlp.classes_\n",
    "\n",
    "# 極簡化配置：只使用單層，參數數量 < 樣本數量\n",
    "# 目標：參數/樣本比例 < 1.0\n",
    "n_features = X_train_scaled.shape[1]  # 9個特徵\n",
    "n_classes = len(le.classes_)  # 3個類別\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"模型複雜度分析\")\n",
    "print(\"=\"*60)\n",
    "print(f\"特徵數量: {n_features}\")\n",
    "print(f\"類別數量: {n_classes}\")\n",
    "print(f\"訓練樣本數: {len(X_train)}\")\n",
    "print(\"\\n不同架構的參數數量估算:\")\n",
    "\n",
    "# 計算不同架構的參數數量\n",
    "architectures = [(3,), (4,), (5,), (6,), (8,), (10,)]\n",
    "for arch in architectures:\n",
    "    if len(arch) == 1:\n",
    "        n_params = n_features * arch[0] + arch[0] * n_classes + arch[0] + n_classes\n",
    "        ratio = n_params / len(X_train)\n",
    "        status = \"✓\" if ratio < 1.0 else \"✗\"\n",
    "        print(f\"  {arch}: {n_params} 參數, 比例 {ratio:.2f} {status}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "params = {\n",
    "    'hidden_layer_sizes': [\n",
    "        # 只使用非常小的單層（確保參數 < 樣本數）\n",
    "        (3,), (4,), (5,), (6,), (8,), (10,),\n",
    "    ],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [3.0, 5.0, 10.0, 15.0, 20.0],  # 非常強的正則化\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'beta_1': [0.9],\n",
    "    'beta_2': [0.999],\n",
    "}\n",
    "\n",
    "clf = WeightedMLPClassifier(\n",
    "    random_state=42, \n",
    "    max_iter=3000,\n",
    "    early_stopping=True, \n",
    "    validation_fraction=0.25,\n",
    "    tol=1e-3,\n",
    "    n_iter_no_change=15,\n",
    "    solver='adam',\n",
    "    batch_size='auto'\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    clf, \n",
    "    params, \n",
    "    cv=skf,\n",
    "    n_jobs=-1, \n",
    "    verbose=1,\n",
    "    scoring='balanced_accuracy',\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"開始 Fine-tune 網格搜索（極簡化單層配置）...\")\n",
    "print(\"=\"*60)\n",
    "grid_search.fit(X_train_scaled, y_train_int, sample_weight=sample_weights)\n",
    "\n",
    "best_clf = grid_search.best_estimator_\n",
    "print(f\"\\n最佳參數: {grid_search.best_params_}\")\n",
    "print(f\"最佳交叉驗證 Balanced Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 計算參數數量\n",
    "best_hidden = grid_search.best_params_['hidden_layer_sizes']\n",
    "n_features = X_train_scaled.shape[1]\n",
    "n_classes = len(le.classes_)\n",
    "\n",
    "if isinstance(best_hidden, tuple) and len(best_hidden) == 1:\n",
    "    n_params = n_features * best_hidden[0] + best_hidden[0] * n_classes + best_hidden[0] + n_classes\n",
    "    ratio = n_params / len(X_train)\n",
    "    print(f\"\\n估計參數數量: {n_params}\")\n",
    "    print(f\"訓練樣本數量: {len(X_train)}\")\n",
    "    print(f\"參數/樣本比例: {ratio:.2f}\", end=\"\")\n",
    "    if ratio < 1.0:\n",
    "        print(\" ✓ (符合建議)\")\n",
    "    elif ratio < 1.5:\n",
    "        print(\" ⚠️ (略高，但可接受)\")\n",
    "    else:\n",
    "        print(\" ✗ (仍然太高)\")\n",
    "\n",
    "# 顯示最終使用的網絡架構\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"最終使用的網絡架構\")\n",
    "print(\"=\"*60)\n",
    "best_hidden_layers = grid_search.best_params_['hidden_layer_sizes']\n",
    "print(f\"hidden_layer_sizes: {best_hidden_layers}\")\n",
    "\n",
    "if isinstance(best_hidden_layers, tuple):\n",
    "    if len(best_hidden_layers) == 1:\n",
    "        print(f\"架構類型: 單層MLP\")\n",
    "        print(f\"  隱藏層: {best_hidden_layers[0]} 個神經元\")\n",
    "    else:\n",
    "        print(f\"架構類型: {len(best_hidden_layers)}層MLP\")\n",
    "        for i, neurons in enumerate(best_hidden_layers, 1):\n",
    "            print(f\"  第{i}層隱藏層: {neurons} 個神經元\")\n",
    "\n",
    "print(f\"\\n其他重要參數:\")\n",
    "print(f\"  激活函數: {grid_search.best_params_['activation']}\")\n",
    "print(f\"  正則化參數 (alpha): {grid_search.best_params_['alpha']}\")\n",
    "print(f\"  學習率: {grid_search.best_params_['learning_rate']}\")\n",
    "print(f\"  初始學習率: {grid_search.best_params_['learning_rate_init']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Validation set metrics\n",
    "y_val_pred = best_clf.predict(X_val_scaled)\n",
    "y_val_pred_proba = best_clf.predict_proba(X_val_scaled)\n",
    "y_val_pred_labels = le.inverse_transform(y_val_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Validation Metrics for Fine-tuned MLPClassifier Model\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n混淆矩陣:\")\n",
    "print(confusion_matrix(y_val_int, y_val_pred))\n",
    "print(\"\\n分類報告:\")\n",
    "print(classification_report(y_val, y_val_pred_labels, target_names=list(le.classes_)))\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_val_binarized = label_binarize(y_val_int, classes=[0, 1, 2])\n",
    "print(\"\\n每個類別的 ROC AUC:\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    fpr, tpr, _ = roc_curve(y_val_binarized[:, i], y_val_pred_proba[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"  {class_name} (Class {i}): {roc_auc:.4f}\")\n",
    "\n",
    "macro_roc_auc = roc_auc_score(y_val_int, y_val_pred_proba, multi_class='ovr', average='macro')\n",
    "weighted_roc_auc = roc_auc_score(y_val_int, y_val_pred_proba, multi_class='ovr', average='weighted')\n",
    "val_balanced_acc = balanced_accuracy_score(y_val_int, y_val_pred)\n",
    "\n",
    "print(f\"\\n宏平均 ROC AUC: {macro_roc_auc:.4f}\")\n",
    "print(f\"加權平均 ROC AUC: {weighted_roc_auc:.4f}\")\n",
    "print(f\"Balanced Accuracy: {val_balanced_acc:.4f}\")\n",
    "\n",
    "# Test set metrics\n",
    "y_test_pred = best_clf.predict(X_test_scaled)\n",
    "y_test_pred_proba = best_clf.predict_proba(X_test_scaled)\n",
    "y_test_pred_labels = le.inverse_transform(y_test_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Test Metrics for Fine-tuned MLPClassifier Model\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n混淆矩陣:\")\n",
    "print(confusion_matrix(y_test_int, y_test_pred))\n",
    "print(\"\\n分類報告:\")\n",
    "print(classification_report(y_test, y_test_pred_labels, target_names=list(le.classes_)))\n",
    "\n",
    "print(\"\\n每個類別的 ROC AUC:\")\n",
    "y_test_binarized = label_binarize(y_test_int, classes=[0, 1, 2])\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_test_pred_proba[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"  {class_name} (Class {i}): {roc_auc:.4f}\")\n",
    "\n",
    "macro_roc_auc_test = roc_auc_score(y_test_int, y_test_pred_proba, multi_class='ovr', average='macro')\n",
    "weighted_roc_auc_test = roc_auc_score(y_test_int, y_test_pred_proba, multi_class='ovr', average='weighted')\n",
    "test_balanced_acc = balanced_accuracy_score(y_test_int, y_test_pred)\n",
    "\n",
    "print(f\"\\n宏平均 ROC AUC: {macro_roc_auc_test:.4f}\")\n",
    "print(f\"加權平均 ROC AUC: {weighted_roc_auc_test:.4f}\")\n",
    "print(f\"Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "\n",
    "# 過擬合分析\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"過擬合分析\")\n",
    "print(\"=\"*60)\n",
    "overfitting_gap = val_balanced_acc - test_balanced_acc\n",
    "print(f\"驗證集 Balanced Accuracy: {val_balanced_acc:.4f}\")\n",
    "print(f\"測試集 Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "print(f\"過擬合差距: {overfitting_gap:.4f}\")\n",
    "\n",
    "if overfitting_gap > 0.15:\n",
    "    print(\"⚠️ 警告：存在明顯過擬合（差距 > 0.15）\")\n",
    "    print(\"   建議：考慮使用更簡單的模型（如RandomForest、Logistic Regression）\")\n",
    "elif overfitting_gap > 0.10:\n",
    "    print(\"⚠️ 注意：存在一定過擬合（差距 > 0.10）\")\n",
    "else:\n",
    "    print(\"✓ 過擬合程度在可接受範圍內\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f7e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208f93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b697d05b",
   "metadata": {},
   "source": [
    "### 多尺度特徵提取 CNN 模型（類似 Receptive Field）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b1049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "數據分割信息\n",
      "============================================================\n",
      "總樣本數: 88\n",
      "訓練集樣本數: 30 (34.1%)\n",
      "驗證集樣本數: 31 (35.2%)\n",
      "測試集樣本數: 27 (30.7%)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "改進版多尺度特徵提取 CNN（類似 Receptive Field）\n",
      "============================================================\n",
      "\n",
      "類別分布: {'A': np.int64(12), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "Balanced 權重: {'A': np.float64(0.8333333333333334), 'C': np.float64(1.0), 'F': np.float64(1.25)}\n",
      "Inverse frequency 權重: {'A': np.float64(0.8108108108108107), 'C': np.float64(0.972972972972973), 'F': np.float64(1.2162162162162162)}\n",
      "\n",
      "使用設備: cuda\n",
      "模型參數數量: 261\n",
      "訓練樣本數: 30\n",
      "參數/樣本比例: 8.70\n",
      "\n",
      "============================================================\n",
      "開始訓練...\n",
      "============================================================\n",
      "使用 Focal Loss\n",
      "Epoch 20/300, Train Loss: 0.6046, Val Loss: 0.4866, Val Acc: 0.4194, Val Balanced Acc: 0.4917\n",
      "Epoch 40/300, Train Loss: 0.5279, Val Loss: 0.4617, Val Acc: 0.4194, Val Balanced Acc: 0.4917\n",
      "Early stopping at epoch 42\n",
      "\n",
      "最佳驗證集準確率: 0.4516\n",
      "最佳驗證集 Balanced Accuracy: 0.5000\n",
      "\n",
      "============================================================\n",
      "Validation Metrics for Improved Multi-Scale CNN\n",
      "============================================================\n",
      "\n",
      "混淆矩陣:\n",
      "[[0 7 6]\n",
      " [0 6 4]\n",
      " [0 1 7]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00        13\n",
      "           C       0.43      0.60      0.50        10\n",
      "           F       0.41      0.88      0.56         8\n",
      "\n",
      "    accuracy                           0.42        31\n",
      "   macro avg       0.28      0.49      0.35        31\n",
      "weighted avg       0.24      0.42      0.31        31\n",
      "\n",
      "\n",
      "每個類別的 ROC AUC:\n",
      "  A (Class 0): 0.5385\n",
      "  C (Class 1): 0.7286\n",
      "  F (Class 2): 0.7228\n",
      "\n",
      "宏平均 ROC AUC: 0.6633\n",
      "加權平均 ROC AUC: 0.6474\n",
      "Balanced Accuracy: 0.4917\n",
      "\n",
      "============================================================\n",
      "Test Metrics for Improved Multi-Scale CNN\n",
      "============================================================\n",
      "\n",
      "混淆矩陣:\n",
      "[[0 7 4]\n",
      " [0 7 2]\n",
      " [0 6 1]]\n",
      "\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00        11\n",
      "           C       0.35      0.78      0.48         9\n",
      "           F       0.14      0.14      0.14         7\n",
      "\n",
      "    accuracy                           0.30        27\n",
      "   macro avg       0.16      0.31      0.21        27\n",
      "weighted avg       0.15      0.30      0.20        27\n",
      "\n",
      "\n",
      "每個類別的 ROC AUC:\n",
      "  A (Class 0): 0.4318\n",
      "  C (Class 1): 0.4753\n",
      "  F (Class 2): 0.4714\n",
      "\n",
      "宏平均 ROC AUC: 0.4595\n",
      "加權平均 ROC AUC: 0.4566\n",
      "Balanced Accuracy: 0.3069\n",
      "\n",
      "============================================================\n",
      "過擬合分析\n",
      "============================================================\n",
      "驗證集 Balanced Accuracy: 0.4917\n",
      "測試集 Balanced Accuracy: 0.3069\n",
      "過擬合差距: 0.1848\n",
      "⚠️ 警告：存在明顯過擬合（差距 > 0.15）\n",
      "   建議：增加 dropout 率或減少模型複雜度\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "類別預測分布分析\n",
      "============================================================\n",
      "\n",
      "驗證集預測分布:\n",
      "真實分布: {'A': np.int64(13), 'C': np.int64(10), 'F': np.int64(8)}\n",
      "預測分布: {'A': np.int64(0), 'C': np.int64(14), 'F': np.int64(17)}\n",
      "\n",
      "測試集預測分布:\n",
      "真實分布: {'A': np.int64(11), 'C': np.int64(9), 'F': np.int64(7)}\n",
      "預測分布: {'A': np.int64(0), 'C': np.int64(20), 'F': np.int64(7)}\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 完整訓練程式：改進版多尺度 CNN\n",
    "# ============================================\n",
    "\n",
    "# ============================================\n",
    "# 步驟 1: 資料載入和預處理\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 設置數據路徑\n",
    "base_dir = r'/ibmnas/427/bachelors/b12901077/eeg'\n",
    "dataset_dir = os.path.join(base_dir, 'ds004504')\n",
    "\n",
    "# 讀取特徵數據\n",
    "features_df = pd.read_csv(os.path.join(base_dir, \"features_tv.csv\"))\n",
    "# 讀取參與者信息\n",
    "participants = pd.read_csv(os.path.join(dataset_dir, \"participants.tsv\"), delimiter='\\t')\n",
    "\n",
    "# 合併數據\n",
    "data = features_df.merge(participants, left_index=True, right_index=True)\n",
    "\n",
    "# 定義特徵字典\n",
    "features = {\n",
    "    'stationary_ratio': 'Stationary Ratio',\n",
    "    'Tik-norm': 'Tik-norm',\n",
    "    'Total_Variation': 'Total Variation',\n",
    "    'graph_energy': 'Graph Energy',\n",
    "    'spectral_entropy': 'Spectral Entropy',\n",
    "    'signal_energy': 'Signal Energy',\n",
    "    'signal_power': 'Signal Power',\n",
    "    'avg_degree': 'Average Degree',\n",
    "    'diffusion_distance': 'Diffusion Distance',\n",
    "}\n",
    "\n",
    "# 準備特徵和標籤\n",
    "X = data[list(features.keys())].copy()\n",
    "y = data['Group'].copy()\n",
    "\n",
    "# 數據清理\n",
    "for col in X.columns:\n",
    "    first_val = X[col].iloc[0] if len(X) > 0 else None\n",
    "    if isinstance(first_val, str):\n",
    "        def safe_convert(x):\n",
    "            if pd.isna(x):\n",
    "                return np.nan\n",
    "            if isinstance(x, str):\n",
    "                try:\n",
    "                    parsed = ast.literal_eval(x)\n",
    "                    if isinstance(parsed, (list, tuple, np.ndarray)):\n",
    "                        return float(parsed[0]) if len(parsed) > 0 else np.nan\n",
    "                    return float(parsed)\n",
    "                except:\n",
    "                    try:\n",
    "                        return float(x)\n",
    "                    except:\n",
    "                        try:\n",
    "                            parsed = eval('[' + ','.join(x.strip('[]').split()) + ']')\n",
    "                            return float(parsed[0]) if len(parsed) > 0 else np.nan\n",
    "                        except:\n",
    "                            return np.nan\n",
    "            try:\n",
    "                return float(x) if pd.notna(x) else np.nan\n",
    "            except:\n",
    "                return np.nan\n",
    "        X[col] = X[col].apply(safe_convert)\n",
    "    else:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "rows_with_all_nan = X.isna().all(axis=1)\n",
    "valid_mask = ~(rows_with_all_nan | y.isna())\n",
    "X = X[valid_mask].copy()\n",
    "y = y[valid_mask].copy()\n",
    "\n",
    "if X.isna().sum().sum() > 0:\n",
    "    for col in X.columns:\n",
    "        if X[col].isna().sum() > 0:\n",
    "            median_val = X[col].median()\n",
    "            X[col] = X[col].fillna(median_val)\n",
    "\n",
    "X = X.astype(float)\n",
    "\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"錯誤：清理後數據為空！請檢查原始數據。\")\n",
    "\n",
    "# 數據分割（目標比例：訓練集 30, 驗證集 31, 測試集 27）\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=27/88, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=31/61, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_val = X_val.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# 標準化\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 編碼標籤\n",
    "le = LabelEncoder()\n",
    "y_train_int = le.fit_transform(y_train)\n",
    "y_val_int = le.transform(y_val)\n",
    "y_test_int = le.transform(y_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"數據分割信息\")\n",
    "print(\"=\"*60)\n",
    "print(f\"總樣本數: {len(X)}\")\n",
    "print(f\"訓練集樣本數: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"驗證集樣本數: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"測試集樣本數: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# 步驟 2: 模型定義\n",
    "# ============================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss 用於處理類別不平衡\"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[targets]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "class ImprovedMultiScaleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    改進版多尺度特徵提取 CNN\n",
    "    針對小樣本優化，參數數量適中\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features=9, n_classes=3, dropout_rate=0.6):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 使用 3 個通道\n",
    "        self.conv_small = nn.Sequential(\n",
    "            nn.Conv1d(1, 3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv_medium = nn.Sequential(\n",
    "            nn.Conv1d(1, 3, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv_large = nn.Sequential(\n",
    "            nn.Conv1d(1, 3, kernel_size=9, padding=4),\n",
    "            nn.BatchNorm1d(3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 融合層\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(3 * 3, 12),  # 9 -> 12\n",
    "            nn.BatchNorm1d(12),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(12, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (batch, 1, 9)\n",
    "        \n",
    "        # 多尺度卷積\n",
    "        small = torch.mean(self.conv_small(x), dim=2)  # (batch, 3)\n",
    "        medium = torch.mean(self.conv_medium(x), dim=2)  # (batch, 3)\n",
    "        large = torch.mean(self.conv_large(x), dim=2)  # (batch, 3)\n",
    "        \n",
    "        # 融合\n",
    "        combined = torch.cat([small, medium, large], dim=1)  # (batch, 9)\n",
    "        output = self.fusion(combined)  # (batch, 3)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 步驟 3: 訓練函數\n",
    "# ============================================\n",
    "def train_model_improved(model, train_loader, val_loader, \n",
    "                         class_weights, n_epochs=300, lr=0.0005, device='cpu', \n",
    "                         use_focal_loss=True):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 計算類別權重\n",
    "    class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "    \n",
    "    # 選擇損失函數\n",
    "    if use_focal_loss:\n",
    "        criterion = FocalLoss(alpha=class_weights_tensor, gamma=2.0)\n",
    "        print(\"使用 Focal Loss\")\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        print(\"使用加權 CrossEntropyLoss\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=15\n",
    "    )\n",
    "    \n",
    "    best_val_balanced_acc = 0\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    max_patience = 40\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # 訓練\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            \n",
    "            # 梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # 驗證\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += y_batch.size(0)\n",
    "                val_correct += (predicted == y_batch).sum().item()\n",
    "                val_preds.extend(predicted.cpu().numpy())\n",
    "                val_labels.extend(y_batch.cpu().numpy())\n",
    "        \n",
    "        val_acc = val_correct / val_total\n",
    "        val_balanced_acc = balanced_accuracy_score(val_labels, val_preds)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # 使用 balanced accuracy 作為早停標準\n",
    "        if val_balanced_acc > best_val_balanced_acc:\n",
    "            best_val_balanced_acc = val_balanced_acc\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= max_patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "                  f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                  f\"Val Balanced Acc: {val_balanced_acc:.4f}\")\n",
    "    \n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, best_val_acc, best_val_balanced_acc\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 步驟 4: 評估函數\n",
    "# ============================================\n",
    "def evaluate_model(model, data_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            \n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return all_preds, all_probs, all_labels, accuracy\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 步驟 5: 主程式執行\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"改進版多尺度特徵提取 CNN（類似 Receptive Field）\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 計算類別權重（使用 inverse frequency）\n",
    "class_counts = np.bincount(y_train_int)\n",
    "total_samples = len(y_train_int)\n",
    "n_classes = len(class_counts)\n",
    "\n",
    "# 方法 1：標準 balanced 權重\n",
    "class_weights_balanced = total_samples / (n_classes * class_counts)\n",
    "\n",
    "# 方法 2：inverse frequency（給少數類別更高權重）\n",
    "class_weights_inv = 1.0 / class_counts\n",
    "class_weights_inv = class_weights_inv / class_weights_inv.sum() * n_classes\n",
    "\n",
    "print(f\"\\n類別分布: {dict(zip(le.classes_, class_counts))}\")\n",
    "print(f\"Balanced 權重: {dict(zip(le.classes_, class_weights_balanced))}\")\n",
    "print(f\"Inverse frequency 權重: {dict(zip(le.classes_, class_weights_inv))}\")\n",
    "\n",
    "# 使用 inverse frequency 權重（給少數類別更高權重）\n",
    "class_weights = class_weights_inv\n",
    "\n",
    "# 轉換為 PyTorch 格式\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "\n",
    "y_train_tensor = torch.LongTensor(y_train_int)\n",
    "y_val_tensor = torch.LongTensor(y_val_int)\n",
    "y_test_tensor = torch.LongTensor(y_test_int)\n",
    "\n",
    "# 創建 DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# 創建模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n使用設備: {device}\")\n",
    "\n",
    "model = ImprovedMultiScaleCNN(\n",
    "    n_features=X_train_scaled.shape[1], \n",
    "    n_classes=3, \n",
    "    dropout_rate=0.6\n",
    ")\n",
    "\n",
    "# 計算參數數量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型參數數量: {total_params}\")\n",
    "print(f\"訓練樣本數: {len(X_train_scaled)}\")\n",
    "print(f\"參數/樣本比例: {total_params / len(X_train_scaled):.2f}\")\n",
    "\n",
    "# 訓練模型\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"開始訓練...\")\n",
    "print(\"=\"*60)\n",
    "trained_model, best_val_acc, best_val_balanced_acc = train_model_improved(\n",
    "    model, train_loader, val_loader,\n",
    "    class_weights=class_weights,\n",
    "    n_epochs=300,\n",
    "    lr=0.0005,\n",
    "    device=device,\n",
    "    use_focal_loss=True  # 使用 Focal Loss\n",
    ")\n",
    "\n",
    "print(f\"\\n最佳驗證集準確率: {best_val_acc:.4f}\")\n",
    "print(f\"最佳驗證集 Balanced Accuracy: {best_val_balanced_acc:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 步驟 6: 驗證集評估\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Validation Metrics for Improved Multi-Scale CNN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "val_preds, val_probs, val_labels, val_acc = evaluate_model(trained_model, val_loader, device)\n",
    "val_pred_labels = le.inverse_transform(val_preds)\n",
    "val_true_labels = le.inverse_transform(val_labels)\n",
    "\n",
    "print(\"\\n混淆矩陣:\")\n",
    "print(confusion_matrix(val_labels, val_preds))\n",
    "\n",
    "print(\"\\n分類報告:\")\n",
    "print(classification_report(val_true_labels, val_pred_labels, target_names=list(le.classes_)))\n",
    "\n",
    "# ROC AUC\n",
    "val_binarized = label_binarize(val_labels, classes=[0, 1, 2])\n",
    "val_probs_array = np.array(val_probs)\n",
    "\n",
    "print(\"\\n每個類別的 ROC AUC:\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    fpr, tpr, _ = roc_curve(val_binarized[:, i], val_probs_array[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"  {class_name} (Class {i}): {roc_auc:.4f}\")\n",
    "\n",
    "macro_roc_auc_val = roc_auc_score(val_labels, val_probs_array, multi_class='ovr', average='macro')\n",
    "weighted_roc_auc_val = roc_auc_score(val_labels, val_probs_array, multi_class='ovr', average='weighted')\n",
    "val_balanced_acc = balanced_accuracy_score(val_labels, val_preds)\n",
    "\n",
    "print(f\"\\n宏平均 ROC AUC: {macro_roc_auc_val:.4f}\")\n",
    "print(f\"加權平均 ROC AUC: {weighted_roc_auc_val:.4f}\")\n",
    "print(f\"Balanced Accuracy: {val_balanced_acc:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 步驟 7: 測試集評估\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Test Metrics for Improved Multi-Scale CNN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_preds, test_probs, test_labels, test_acc = evaluate_model(trained_model, test_loader, device)\n",
    "test_pred_labels = le.inverse_transform(test_preds)\n",
    "test_true_labels = le.inverse_transform(test_labels)\n",
    "\n",
    "print(\"\\n混淆矩陣:\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n",
    "\n",
    "print(\"\\n分類報告:\")\n",
    "print(classification_report(test_true_labels, test_pred_labels, target_names=list(le.classes_)))\n",
    "\n",
    "# ROC AUC\n",
    "test_binarized = label_binarize(test_labels, classes=[0, 1, 2])\n",
    "test_probs_array = np.array(test_probs)\n",
    "\n",
    "print(\"\\n每個類別的 ROC AUC:\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    fpr, tpr, _ = roc_curve(test_binarized[:, i], test_probs_array[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"  {class_name} (Class {i}): {roc_auc:.4f}\")\n",
    "\n",
    "macro_roc_auc_test = roc_auc_score(test_labels, test_probs_array, multi_class='ovr', average='macro')\n",
    "weighted_roc_auc_test = roc_auc_score(test_labels, test_probs_array, multi_class='ovr', average='weighted')\n",
    "test_balanced_acc = balanced_accuracy_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"\\n宏平均 ROC AUC: {macro_roc_auc_test:.4f}\")\n",
    "print(f\"加權平均 ROC AUC: {weighted_roc_auc_test:.4f}\")\n",
    "print(f\"Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 步驟 8: 過擬合分析\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"過擬合分析\")\n",
    "print(\"=\"*60)\n",
    "overfitting_gap = val_balanced_acc - test_balanced_acc\n",
    "print(f\"驗證集 Balanced Accuracy: {val_balanced_acc:.4f}\")\n",
    "print(f\"測試集 Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "print(f\"過擬合差距: {overfitting_gap:.4f}\")\n",
    "\n",
    "if overfitting_gap > 0.15:\n",
    "    print(\"⚠️ 警告：存在明顯過擬合（差距 > 0.15）\")\n",
    "    print(\"   建議：增加 dropout 率或減少模型複雜度\")\n",
    "elif overfitting_gap > 0.10:\n",
    "    print(\"⚠️ 注意：存在一定過擬合（差距 > 0.10）\")\n",
    "else:\n",
    "    print(\"✓ 過擬合程度在可接受範圍內\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# 步驟 9: 類別預測分布分析\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"類別預測分布分析\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n驗證集預測分布:\")\n",
    "val_pred_counts = {le.classes_[i]: np.sum(np.array(val_preds) == i) for i in range(len(le.classes_))}\n",
    "val_true_counts = {le.classes_[i]: np.sum(np.array(val_labels) == i) for i in range(len(le.classes_))}\n",
    "print(f\"真實分布: {val_true_counts}\")\n",
    "print(f\"預測分布: {val_pred_counts}\")\n",
    "\n",
    "print(\"\\n測試集預測分布:\")\n",
    "test_pred_counts = {le.classes_[i]: np.sum(np.array(test_preds) == i) for i in range(len(le.classes_))}\n",
    "test_true_counts = {le.classes_[i]: np.sum(np.array(test_labels) == i) for i in range(len(le.classes_))}\n",
    "print(f\"真實分布: {test_true_counts}\")\n",
    "print(f\"預測分布: {test_pred_counts}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
